{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 0) Work Directory and setup"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["New actual directory: /Users/jyoung/Doctorado/embryo_classification/\n"]}],"source":["import os\n","# Obtiene el nuevo directorio actual despuÃ©s del cambio\n","new_directory = '/Users/jyoung/Doctorado/embryo_classification/'\n","os.chdir(new_directory)\n","print(\"New actual directory:\", new_directory)\n","\n","# Elimino warnings molestas\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# 1) Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-23 23:09:47.740829: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["# Data Manipulation and Visualization\n","import numpy as np                  # NumPy for numerical operations and array manipulations\n","import matplotlib.pyplot as plt     # Matplotlib for creating visualizations\n","from pathlib import Path            # Pathlib for working with file paths\n","import openpyxl                     # Openpyxl for reading and writing Excel files\n","import json                         # JSON for data serialization\n","from tqdm import tqdm               # tqdm for creating progress bars\n","from typing import Tuple, List, Union  # Typing for type hinting in function signatures\n","\n","# Model Training and Evaluation\n","from sklearn.experimental import enable_halving_search_cv  # noqa\n","from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold  # Hyperparameter tuning and cross-validation\n","from sklearn.tree import DecisionTreeClassifier  # DecisionTreeClassifier for tree-based models\n","from sklearn.ensemble import RandomForestClassifier  # RandomForestClassifier for ensemble learning\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Metrics for model evaluation\n","from sklearn.svm import SVC          # Support Vector Classification\n","from sklearn.neural_network import MLPClassifier  # Multi-layer Perceptron classifier\n","import xgboost as xgb               # XGBoost for gradient boosting\n","from sklearn.naive_bayes import GaussianNB  # Gaussian Naive Bayes classifier\n","from sklearn.decomposition import PCA  # Principal Component Analysis for dimensionality reduction\n","from sklearn.model_selection import train_test_split  # Splitting data for training and testing\n","from xgboost import plot_tree       # Plotting decision trees in XGBoost\n","from sklearn.model_selection import cross_val_score  # Cross-validation for model evaluation\n","from sklearn.model_selection import KFold  # K-Fold cross-validation\n","\n","# Image Processing and Feature Extraction\n","from skimage.feature import graycomatrix, graycoprops  # Image texture features using co-occurrence matrix\n","from skimage import exposure         # Image exposure adjustment\n","from scipy import ndimage            # Multi-dimensional image processing\n","import skimage.measure              # Image measurement and analysis\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img  # Image preprocessing using Keras\n","\n","# Signal Processing\n","from scipy.signal import find_peaks, savgol_filter  # Signal processing functions in SciPy\n","\n","\n","\n","###############\n","\n","from skimage.transform import resize\n","from tensorflow.keras.applications import (\n","    VGG16, ResNet50, InceptionV3, MobileNetV2\n",")\n","from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg16\n","from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet50\n","from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inceptionv3\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobilenetv2\n","from tensorflow.keras.models import Model\n"]},{"cell_type":"markdown","metadata":{"id":"ccfa4897"},"source":["# 2) Functions"]},{"cell_type":"markdown","metadata":{},"source":["## Image functions"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def load_image(region: str, index: int) -> np.ndarray:\n","    \"\"\"\n","    Loads and preprocesses an image from a specified region and index.\n","\n","    Parameters:\n","    - region (str): Name of the region.\n","    - index (int): Index of the image.\n","\n","    Returns:\n","    - chosen_region (np.ndarray): Preprocessed image.\n","    \"\"\"\n","    chosen_region = img_to_array(load_img(str(region) + '/' + str(index) + '.bmp', grayscale=True)).squeeze() / 255.0\n","    return chosen_region\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training functions"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def apply_PCA(X, n_components):\n","    \"\"\"\n","    Applies Principal Component Analysis (PCA) to the input data.\n","\n","    Parameters:\n","    - X (array-like): Input data.\n","    - n_components (int): Number of components to keep.\n","\n","    Returns:\n","    - X_pca (array-like): Transformed data after PCA.\n","    \"\"\"\n","    # Apply PCA to the training set\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Get the variance explained by each principal component\n","    explained_variance_ratio = pca.explained_variance_ratio_\n","\n","    cumulative_variance = np.cumsum(explained_variance_ratio)\n","\n","    # Create the plot of cumulative variance\n","    plt.plot(range(1, n_components + 1), cumulative_variance, marker='o', linestyle='-', color='b')\n","    plt.title('Cumulative Variance of Principal Components')\n","    plt.xlabel('Number of Principal Components')\n","    plt.ylabel('Cumulative Variance')\n","    plt.grid(True)\n","    plt.show()\n","    \n","    return X_pca\n","\n","\n","def run_halving_grid_search(X, y, clf, param_grid, scoring='accuracy', cv_splits=5, random_state=42, factor=3):\n","    \"\"\"\n","    Runs a halving grid search for hyperparameter tuning.\n","\n","    Parameters:\n","    - X (array-like): Input features.\n","    - y (array-like): Target variable.\n","    - clf: Classifier or regressor object.\n","    - param_grid (dict): Dictionary with hyperparameter names as keys and lists of hyperparameter settings to try.\n","    - scoring (str): Scoring metric for cross-validation (default is 'accuracy').\n","    - cv_splits (int): Number of cross-validation splits (default is 5).\n","    - random_state (int): Random seed for reproducibility (default is 42).\n","    - factor (int): Reduction factor for each iteration of halving (default is 3).\n","\n","    Returns:\n","    - y_pred (array-like): Predicted labels.\n","    - accuracy (float): Mean accuracy across cross-validation folds.\n","    - std_dev (float): Standard deviation of accuracy across cross-validation folds.\n","    \"\"\"\n","    # Create the StratifiedKFold object for stratified data splitting\n","    stratified_kf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n","\n","    # Create the HalvingGridSearchCV object\n","    halving_grid_search = HalvingGridSearchCV(clf, param_grid, scoring=scoring, cv=stratified_kf, factor=factor)\n","\n","    # Perform grid search with cross-validation\n","    tqdm(halving_grid_search.fit(X, y))\n","\n","    # Get the best model from the grid search\n","    best_clf = halving_grid_search.best_estimator_\n","\n","    # Print the best parameters found\n","    print(\"Best parameters:\", halving_grid_search.best_params_)\n","\n","    # Get cross-validation results\n","    cv_results = halving_grid_search.cv_results_\n","\n","    # Print the mean value and standard deviation\n","    accuracy = np.mean(cv_results[\"mean_test_score\"])\n","    std_dev = np.std(cv_results[\"mean_test_score\"])\n","    print(\"\\nMean Accuracy in cross-validation:\", accuracy)\n","    print(\"Standard Deviation of Accuracy in cross-validation:\", std_dev)\n","\n","    # Predict labels on the full dataset (last iteration)\n","    y_pred = best_clf.predict(X)\n","\n","    return y_pred, accuracy, std_dev\n"]},{"cell_type":"markdown","metadata":{},"source":["## Embedding functions"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def convert(x):\n","    \"\"\"\n","    Converts a label to its corresponding numeric value.\n","\n","    Parameters:\n","    - x (str): Input label.\n","\n","    Returns:\n","    - int: Numeric value corresponding to the input label.\n","    \"\"\"\n","    if x == 'A':\n","        return 0\n","    if x == 'B':\n","        return 1\n","    if x == 'C':\n","        return 2\n","\n","def flatten(lista):\n","    lista_aplanada = []\n","    [lista_aplanada.extend(sublista) for sublista in lista]\n","    return lista_aplanada\n","\n","\n","def obtener_embeddings_multi_redes(img_numpy):\n","    # Redimensionar la imagen a 300x300\n","    img_resized = resize(img_numpy, (300, 300, 3), anti_aliasing=True)\n","\n","    # Convertir a formato aceptado por las distintas redes\n","    img_preprocessed_vgg16 = preprocess_vgg16(img_resized)\n","    img_preprocessed_resnet50 = preprocess_resnet50(img_resized)\n","    img_preprocessed_inceptionv3 = preprocess_inceptionv3(img_resized)\n","    img_preprocessed_mobilenetv2 = preprocess_mobilenetv2(img_resized)\n","\n","    # Expandir dimensiones para crear un lote de una sola imagen para cada red\n","    img_preprocessed_vgg16 = np.expand_dims(img_preprocessed_vgg16, axis=0)\n","    img_preprocessed_resnet50 = np.expand_dims(img_preprocessed_resnet50, axis=0)\n","    img_preprocessed_inceptionv3 = np.expand_dims(img_preprocessed_inceptionv3, axis=0)\n","    img_preprocessed_mobilenetv2 = np.expand_dims(img_preprocessed_mobilenetv2, axis=0)\n","\n","    # Cargar las redes pre-entrenadas sin la capa de salida\n","    redes = [\n","        (VGG16(weights='imagenet', include_top=False), img_preprocessed_vgg16),\n","        (ResNet50(weights='imagenet', include_top=False), img_preprocessed_resnet50),\n","        (InceptionV3(weights='imagenet', include_top=False), img_preprocessed_inceptionv3),\n","        (MobileNetV2(weights='imagenet', include_top=False), img_preprocessed_mobilenetv2)\n","    ]\n","\n","    embeddings = []\n","    for red, img_preprocessed in redes:\n","        embeddings_layer = red.output\n","        model = Model(inputs=red.input, outputs=embeddings_layer)\n","        embeddings.append(flatten(model.predict(img_preprocessed)))\n","\n","    return embeddings\n"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Embedding extraction"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 543ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 724ms/step\n","1/1 [==============================] - 0s 408ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x195b91ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 413ms/step\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x195b927a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 1s 605ms/step\n","1/1 [==============================] - 1s 876ms/step\n","1/1 [==============================] - 0s 414ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 694ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 415ms/step\n","1/1 [==============================] - 1s 593ms/step\n","1/1 [==============================] - 1s 693ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 411ms/step\n","1/1 [==============================] - 1s 594ms/step\n","1/1 [==============================] - 1s 705ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 416ms/step\n","1/1 [==============================] - 1s 603ms/step\n","1/1 [==============================] - 1s 698ms/step\n","1/1 [==============================] - 0s 403ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 455ms/step\n","1/1 [==============================] - 1s 589ms/step\n","1/1 [==============================] - 1s 870ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 404ms/step\n","1/1 [==============================] - 1s 593ms/step\n","1/1 [==============================] - 1s 694ms/step\n","1/1 [==============================] - 0s 405ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 425ms/step\n","1/1 [==============================] - 1s 595ms/step\n","1/1 [==============================] - 1s 696ms/step\n","1/1 [==============================] - 0s 408ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 416ms/step\n","1/1 [==============================] - 1s 592ms/step\n","1/1 [==============================] - 1s 698ms/step\n","1/1 [==============================] - 0s 407ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 413ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 413ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 413ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 405ms/step\n","1/1 [==============================] - 1s 614ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 408ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 597ms/step\n","1/1 [==============================] - 1s 714ms/step\n","1/1 [==============================] - 0s 403ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 431ms/step\n","1/1 [==============================] - 1s 596ms/step\n","1/1 [==============================] - 1s 699ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 596ms/step\n","1/1 [==============================] - 1s 713ms/step\n","1/1 [==============================] - 0s 407ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 412ms/step\n","1/1 [==============================] - 1s 596ms/step\n","1/1 [==============================] - 1s 696ms/step\n","1/1 [==============================] - 0s 407ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 403ms/step\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 1s 703ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 422ms/step\n","1/1 [==============================] - 1s 619ms/step\n","1/1 [==============================] - 1s 940ms/step\n","1/1 [==============================] - 0s 448ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 456ms/step\n","1/1 [==============================] - 1s 624ms/step\n","1/1 [==============================] - 1s 701ms/step\n","1/1 [==============================] - 0s 408ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 422ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 700ms/step\n","1/1 [==============================] - 0s 418ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 711ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 700ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 560ms/step\n","1/1 [==============================] - 1s 598ms/step\n","1/1 [==============================] - 1s 703ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 598ms/step\n","1/1 [==============================] - 1s 738ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 403ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 702ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 432ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 407ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 706ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 412ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 408ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 877ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 402ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 699ms/step\n","1/1 [==============================] - 0s 407ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 421ms/step\n","1/1 [==============================] - 1s 598ms/step\n","1/1 [==============================] - 1s 703ms/step\n","1/1 [==============================] - 0s 408ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 405ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 413ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 561ms/step\n","1/1 [==============================] - 1s 613ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 414ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 427ms/step\n","1/1 [==============================] - 1s 595ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 421ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 413ms/step\n","1/1 [==============================] - 1s 604ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 417ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 434ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 703ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 412ms/step\n","1/1 [==============================] - 1s 594ms/step\n","1/1 [==============================] - 1s 706ms/step\n","1/1 [==============================] - 0s 408ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 434ms/step\n","1/1 [==============================] - 1s 606ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 604ms/step\n","1/1 [==============================] - 1s 891ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 697ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 434ms/step\n","1/1 [==============================] - 1s 598ms/step\n","1/1 [==============================] - 1s 700ms/step\n","1/1 [==============================] - 0s 417ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 408ms/step\n","1/1 [==============================] - 1s 621ms/step\n","1/1 [==============================] - 1s 702ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 603ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 569ms/step\n","1/1 [==============================] - 1s 609ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 594ms/step\n","1/1 [==============================] - 1s 697ms/step\n","1/1 [==============================] - 0s 416ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 404ms/step\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 1s 712ms/step\n","1/1 [==============================] - 0s 414ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 430ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 414ms/step\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 414ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 437ms/step\n","1/1 [==============================] - 1s 605ms/step\n","1/1 [==============================] - 1s 711ms/step\n","1/1 [==============================] - 0s 417ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 408ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 888ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 606ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 413ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 426ms/step\n","1/1 [==============================] - 1s 604ms/step\n","1/1 [==============================] - 1s 701ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 610ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 418ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 413ms/step\n","1/1 [==============================] - 1s 641ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 427ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 567ms/step\n","1/1 [==============================] - 1s 606ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 401ms/step\n","1/1 [==============================] - 1s 597ms/step\n","1/1 [==============================] - 1s 700ms/step\n","1/1 [==============================] - 0s 420ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 716ms/step\n","1/1 [==============================] - 0s 413ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 424ms/step\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 1s 703ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 415ms/step\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 416ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 414ms/step\n","1/1 [==============================] - 1s 630ms/step\n","1/1 [==============================] - 1s 726ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 407ms/step\n","1/1 [==============================] - 1s 598ms/step\n","1/1 [==============================] - 1s 892ms/step\n","1/1 [==============================] - 0s 417ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 414ms/step\n","1/1 [==============================] - 1s 598ms/step\n","1/1 [==============================] - 1s 701ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 429ms/step\n","1/1 [==============================] - 1s 606ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 411ms/step\n","1/1 [==============================] - 1s 616ms/step\n","1/1 [==============================] - 1s 711ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 407ms/step\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 1s 711ms/step\n","1/1 [==============================] - 0s 417ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 603ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 411ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 413ms/step\n","1/1 [==============================] - 1s 595ms/step\n","1/1 [==============================] - 1s 889ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 404ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 429ms/step\n","1/1 [==============================] - 1s 608ms/step\n","1/1 [==============================] - 1s 714ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 608ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 409ms/step\n","1/1 [==============================] - 1s 612ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 417ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 403ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 714ms/step\n","1/1 [==============================] - 0s 409ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 405ms/step\n","1/1 [==============================] - 1s 609ms/step\n","1/1 [==============================] - 1s 720ms/step\n","1/1 [==============================] - 0s 469ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 666ms/step\n","1/1 [==============================] - 1s 643ms/step\n","1/1 [==============================] - 1s 715ms/step\n","1/1 [==============================] - 0s 420ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 411ms/step\n","1/1 [==============================] - 1s 608ms/step\n","1/1 [==============================] - 1s 704ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 415ms/step\n","1/1 [==============================] - 1s 606ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 415ms/step\n","1/1 [==============================] - 1s 612ms/step\n","1/1 [==============================] - 1s 716ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 601ms/step\n","1/1 [==============================] - 1s 886ms/step\n","1/1 [==============================] - 0s 424ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 406ms/step\n","1/1 [==============================] - 1s 599ms/step\n","1/1 [==============================] - 1s 700ms/step\n","1/1 [==============================] - 0s 418ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 462ms/step\n","1/1 [==============================] - 1s 614ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 412ms/step\n","1/1 [==============================] - 1s 611ms/step\n","1/1 [==============================] - 1s 707ms/step\n","1/1 [==============================] - 0s 415ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 1s 617ms/step\n","1/1 [==============================] - 1s 708ms/step\n","1/1 [==============================] - 0s 410ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 1s 567ms/step\n","1/1 [==============================] - 1s 603ms/step\n","1/1 [==============================] - 1s 709ms/step\n","1/1 [==============================] - 0s 412ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 412ms/step\n","1/1 [==============================] - 1s 600ms/step\n","1/1 [==============================] - 1s 699ms/step\n","1/1 [==============================] - 0s 420ms/step\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","1/1 [==============================] - 0s 413ms/step\n","1/1 [==============================] - 1s 609ms/step\n","1/1 [==============================] - 1s 711ms/step\n","1/1 [==============================] - 0s 414ms/step\n"]}],"source":["n_data = 250\n","n_data = 30\n","features_ICM = []\n","features_TE = []\n","features_ZP = []\n","all_features = []\n","\n","for index in np.arange(1, n_data):\n","\n","    img_ICM = load_image('data/BlastsOnline/GT_ICM', index)\n","    img_TE = load_image('data/BlastsOnline/GT_TE', index)\n","    img_ZP = load_image('data/BlastsOnline/GT_ZP', index)\n","    img_Blast = load_image('data/BlastsOnline/Images', index)\n","\n","    images = [img_ICM, img_ZP, img_TE]*img_Blast\n","\n","    # Obtener los embeddings\n","    embeddings_ICM = obtener_embeddings_multi_redes(images[0])[0]\n","    embeddings_ICM_reshaped = np.array(embeddings_ICM).reshape(-1)\n","    embeddings_TE = obtener_embeddings_multi_redes(images[1])[0]\n","    embeddings_TE_reshaped = np.array(embeddings_TE).reshape(-1)\n","    embeddings_ZP = obtener_embeddings_multi_redes(images[2])[0]\n","    embeddings_ZP_reshaped = np.array(embeddings_ZP).reshape(-1)\n","\n","    total_embeddings = np.hstack((embeddings_ICM_reshaped, embeddings_TE_reshaped, embeddings_ZP_reshaped))\n","\n","    features_ICM.append(embeddings_ICM_reshaped)\n","    features_TE.append(embeddings_TE_reshaped)\n","    features_ZP.append(embeddings_ZP_reshaped)\n","    all_features.append(total_embeddings)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"Object of type ndarray is not JSON serializable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/jyoung/Doctorado/embryo_classification/notebooks/embedded_embryo_classifier.ipynb Celda 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/embryo_classification/notebooks/embedded_embryo_classifier.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdata/embedded_features/features_ICM.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m archivo_json:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/embryo_classification/notebooks/embedded_embryo_classifier.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     json\u001b[39m.\u001b[39;49mdump(features_ICM, archivo_json)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/embryo_classification/notebooks/embedded_embryo_classifier.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdata/embedded_features/features_TE.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m archivo_json:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/embryo_classification/notebooks/embedded_embryo_classifier.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(features_TE, archivo_json)\n","File \u001b[0;32m~/anaconda3/envs/embryo_segmentation/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(skipkeys\u001b[39m=\u001b[39mskipkeys, ensure_ascii\u001b[39m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[39m=\u001b[39mcheck_circular, allow_nan\u001b[39m=\u001b[39mallow_nan, indent\u001b[39m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[39m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[39m=\u001b[39mdefault, sort_keys\u001b[39m=\u001b[39msort_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\u001b[39m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n","File \u001b[0;32m~/anaconda3/envs/embryo_segmentation/lib/python3.10/json/encoder.py:429\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[39myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    428\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 429\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    431\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n","File \u001b[0;32m~/anaconda3/envs/embryo_segmentation/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/embryo_segmentation/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[1;32m    439\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/embryo_segmentation/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"]}],"source":["\n","# Convertir los ndarrays a listas\n","features_ICM = features_ICM.tolist()\n","features_TE = features_TE.tolist()\n","features_ZP = features_ZP.tolist()\n","\n","with open('data/embedded_features/features_ICM.json', 'w') as archivo_json:\n","    json.dump(features_ICM, archivo_json)\n","\n","with open('data/embedded_features/features_TE.json', 'w') as archivo_json:\n","    json.dump(features_TE, archivo_json)\n","\n","with open('data/embedded_features/features_ZP.json', 'w') as archivo_json:\n","    json.dump(features_ZP, archivo_json)\n","\n","\n","\n","with open('data/embedded_features/features_ICM.json', 'r') as archivo:\n","    features_ICM = json.load(archivo)\n","\n","with open('data/embedded_features/features_TE.json', 'r') as archivo:\n","    features_TE = json.load(archivo)\n","\n","with open('data/embedded_features/features_ZP.json', 'r') as archivo:\n","    features_ZP = json.load(archivo)"]},{"cell_type":"markdown","metadata":{"id":"W0e2R7_5v7BV"},"source":["# 4) Load labels"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["xlsx_file = Path('data/BlastsOnline', 'MasterlistAug30-2017.xlsx')\n","wb_obj = openpyxl.load_workbook(xlsx_file) \n","\n","sheet = wb_obj.active\n","\n","blast_quality = []\n","for i in range(2,n_data+1):\n","    blast_quality.append(list(sheet['B'+str(i)].value))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":296,"status":"ok","timestamp":1670526632936,"user":{"displayName":"Juan Diego Young","userId":"16464023669569824356"},"user_tz":180},"id":"J9IVNFobtH1n"},"outputs":[{"name":"stdout","output_type":"stream","text":["124416\n"]}],"source":["def choose_region(zone, all_features):\n","  print(len(all_features[0]))\n","  X_data = np.zeros((n_data-1, len(all_features[0])))\n","  y_ICM = np.zeros(n_data-1)\n","  y_TE = np.zeros(n_data-1)\n","  y_ZP = np.zeros(n_data-1)\n","\n","  for i in np.arange(1,n_data):\n","    y_ICM[i-1] = convert(blast_quality[i-1][1])\n","    y_TE[i-1] = convert(blast_quality[i-1][2])\n","    y_ZP[i-1] = convert(blast_quality[i-1][0])\n","    X_data[i-1] = all_features[i-1]\n","\n","  if zone == 'ICM':\n","    y_data = y_ICM\n","  if zone == 'TE':\n","    y_data = y_TE\n","  if zone == 'ZP':\n","    y_data = y_ZP\n","\n","  return X_data, y_data\n","\n","X,y = choose_region('ICM', all_features)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n"]}],"source":["# Sanity check:\n","\n","print(len(X) == n_data-1)\n","\n","print(len(y) == n_data-1)"]},{"cell_type":"markdown","metadata":{},"source":["# 6) Entrenamiento"]},{"cell_type":"markdown","metadata":{},"source":["## Principal component analysis"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3/klEQVR4nO3dd3hURdvH8e+mh9AhhBa6NKkGEIKACIlSbTwgvQpIJygSBSmP0qRZAEEFLDRFkGIQIggCARUECyBKMwIJXUNPO+8f580+LElgF5Jdkvw+15VLz+zs7H0mm92bmXNmLIZhGIiIiIjkIG6uDkBERETE2ZQAiYiISI6jBEhERERyHCVAIiIikuMoARIREZEcRwmQiIiI5DhKgERERCTHUQIkIiIiOY4SIBEREclxlACJ1S+//ELPnj0pW7YsPj4+5M6dm4ceeoipU6dy4cIFV4d3W+PGjcNisdzVcyMiIhg3blyaj5UpU4YePXrcfWAOOnv2LF5eXjz33HPp1omLiyNXrly0bds2Q17zXvouq9q0aRN16tTBz88Pi8XCl19+mWa948ePY7FYrD9ubm4UKlSIli1bsnPnTrtea9GiRVgsFo4fP55xJ3ALi8WS7ns4ozh6Hln58yQriIqKYty4cfzzzz+uDiXL8nB1AHJ/eP/99xkwYACVKlXipZdeomrVqiQkJLB7927ee+89du7cyapVq1wdZqaIiIhg9uzZaX6BrFq1irx58zotFn9/f9q2bcuXX37JxYsXKVCgQKo6y5Yt49q1a/Tu3TtDXrNPnz488cQTGdJWVmAYBu3bt6dixYqsWbMGPz8/KlWqdNvnDB48mE6dOpGUlMT+/fsZP348TZs2ZefOndSuXfu2z23VqhU7d+6kWLFiGXkaNnbu3EnJkiUzrX1H5eTPE2eJiopi/Pjx9OjRg/z587s6nKzJkBwvKirKcHd3N5544gnj+vXrqR6/ceOGsXr1ahdEZr+xY8cad/t2Hjhw4F0/NzNEREQYgPHOO++k+fjDDz9sBAQEGAkJCff0OleuXLmn52dVJ06cMABjypQpd6x77NgxAzDefPNNm/JNmzYZgNGnT590n3v16lUjOTn5nuO9XyxcuNAAjGPHjt22Xnb4PMkK3nzzTbt+H5K+++dTX1ymdevWhoeHhxEdHW1XfcAYO3ZsqvLSpUsb3bt3tx6nfGBu2rTJ6NOnj1GwYEEjT548RteuXY3Lly8bMTExxn/+8x8jX758RtGiRY0RI0YY8fHx1ud/++23BmB8++23Nq+T8qW0cOFCa1laCdCyZcuMkJAQo2jRooaPj49RuXJl4+WXXzYuX75srdO9e3cDSPWT8qFy8zmdOXPG8PT0NEaPHp3q3A8ePGgAxltvvWUti4mJMfr27WuUKFHC8PT0NMqUKWOMGzfujolLUlKSUbJkSeOhhx5K9diBAwcMwHjppZcMwzCMjRs3Gm3btjVKlChheHt7G+XLlzf69u1rnD171uZ5Kf2zZ88e49lnnzXy589vFC1a9J76LqX//Pz8jD///NNo0aKF4efnZ5QsWdIICwtL9eV3/fp1Y/z48UblypUNb29vo2DBgsajjz5q7Nixw1onOTnZmD17tlGzZk3Dx8fHyJ8/v/Hss88aR44cuW2fpdi2bZvx2GOPGblz5zZ8fX2NBg0aGOvWrUvVDzf/lC5dOt320kuArly5YgBGSEiIYRj/e69v2LDB6Nmzp1G4cGEDMK5du5Zm4tCkSRPjwQcfNH744QfjkUceMXx9fY2yZcsakyZNMpKSkmxe6+LFi0ZYWJhRtmxZw8vLy/D39zdatGhhHDx40Frn1r/JlNfcuHGj0aNHD6NAgQJGrly5jNatW6fqS3vfQ/YmQI5+niQlJRlTpkwxKlWqZD2/rl27Gn///bdNvZQ+i4qKMho0aGD4+PgYpUuXNhYsWGAYhmGsW7fOqF27tuHr62tUq1bNWL9+vc3zU373P/30k/H0008befLkMfLmzWt07tzZOHPmzD3FZM/v8d9//zVGjBhhlClTxvD09DSKFy9uDB06NNXfFGAMHDjQ+Pjjj43KlSsbvr6+Ro0aNYy1a9emOpdbf1I+Kzdt2mQ0adLEKFiwoOHj42MEBgYazzzzTI79R096dA1QDpeUlMTmzZsJCgoiMDAwU16jT58+5MuXj2XLljF69GiWLFnC888/T6tWrahZsyYrVqyge/fuTJ8+nXfeeSfDXvfPP/+kZcuWfPjhh3z99dcMGzaMzz77jDZt2ljrjBkzhnbt2gHmNELKT1rTFf7+/rRu3ZqPPvqI5ORkm8cWLlyIl5cXnTt3BiA2NpZ69eqxYcMGXnvtNdavX0/v3r2ZNGkSzz///G3jdnNzo0ePHvz000/8/PPPqV4HoFevXgAcOXKEBg0aMHfuXDZu3Mhrr73G999/zyOPPEJCQkKqtp955hkqVKjA559/znvvvXdPfZciISGBtm3b0qxZM1avXk2vXr2YOXMmU6ZMsdZJTEykRYsW/Pe//6V169asWrWKRYsWERwcTHR0tLVev379GDZsGM2bN+fLL79kzpw57N+/n+DgYE6fPn3bftu6dSuPPfYY//77Lx9++CFLly4lT548tGnThuXLlwPme3HlypWAOa11t1Mxhw8fBsz3xM169eqFp6cnn3zyCStWrMDT0zPdNmJjY+ncuTNdunRhzZo1tGjRgvDwcD799FNrnUuXLvHII48wb948evbsydq1a3nvvfeoWLEiMTExd4yzd+/euLm5sWTJEmbNmsUPP/zAo48+anPdiKPvodu5m8+TF154gZdffpmQkBDWrFnDf//7X77++muCg4M5d+6cTd3Y2Fh69uxJnz59WL16NdWrV6dXr15MmDCB8PBwRo4cyRdffEHu3Ll56qmnOHXqVKrXe/rpp6lQoQIrVqxg3LhxfPnllzz++OM25+poTHf6PV69epUmTZrw0UcfMWTIENavX8/LL7/MokWLaNu2LYZh2LT51Vdf8e677zJhwgS++OILChYsyNNPP83Ro0cB8308ePBgAFauXGn93HrooYc4fvw4rVq1wsvLiwULFvD1118zefJk/Pz8iI+Pt+t3kmO4OgMT14qNjTUA47nnnrP7OTg4AjR48GCbek899ZQBGDNmzLApr1Wrls2ox72OAN0sOTnZSEhIMLZu3WoAxs8//2x97HZTYLee05o1a6z/sk6RmJhoFC9e3Hj22WetZf369TNy585t/PXXXzbtTZs2zQCM/fv3pxurYRjG0aNHDYvFYgwZMsRalpCQYBQtWtRo2LDhbc/xr7/+MgCbaYaU/nnttddSPe9e+i5lBO2zzz6zeU7Lli2NSpUqWY8//vhjAzDef//9dF9n586dBmBMnz7dpvzvv/82fH19jZEjR6b7XMMwjPr16xtFihQxLl26ZC1LTEw0qlWrZpQsWdI6HZXeqE5aUupOmTLFSEhIMK5fv27s2bPHqFu3rgEYX331lWEY/3uvd+vWLVUb6Y0AAcb3339vU7dq1arG448/bj2eMGGCARiRkZG3jfPWv8mU13z66adt6u3YscMAjNdffz3Ndm73HrJnBMjRz5OUkdMBAwbYlH///fcGYLzyyivWspQ+2717t7Xs/Pnzhru7u+Hr62ucPHnSWr5v3z4DMN5++21rWcr7fPjw4TavtXjxYgMwPv3007uO6U6/x0mTJhlubm7Gjz/+aFNvxYoVBmBERERYywAjICDAiIuLs5bFxsYabm5uxqRJk6xl6U2BpbS5b98+Q25PI0CS6Vq3bm1zXKVKFcC8OPTW8r/++ivDXvfo0aN06tSJokWL4u7ujqenJ02aNAHg4MGDd9VmixYtKFq0qHUkBmDDhg2cOnXKOioDsG7dOpo2bUrx4sVJTEy0/rRo0QIwRytup2zZsjRt2pTFixdb/9W2fv16YmNjbV7nzJkz9O/fn8DAQDw8PPD09KR06dLpnuOzzz5r13k60ncWiyXVyFCNGjVsfpfr16/Hx8fHJvZbrVu3DovFQpcuXWz6rGjRotSsWZMtW7ak+9wrV67w/fff065dO3Lnzm0td3d3p2vXrpw4cYJDhw7Zde5pefnll/H09MTHx4egoCCio6OZN28eLVu2tKlnb/8CFC1alHr16tmUpdVvFStWpHnz5ncVd8qIZIrg4GBKly7Nt99+ay1z9D2UkVLiuPVOy3r16lGlShU2bdpkU16sWDGCgoKsxwULFqRIkSLUqlWL4sWLW8tTPmPS+jy5tU/at2+Ph4eHNRZHY7Ln97hu3TqqVatGrVq1bN7bjz/+OBaLJdV7u2nTpuTJk8d6HBAQQJEiRez6fKxVqxZeXl707duXjz76yDpqJKnpLrAcrnDhwuTKlYtjx45l2msULFjQ5tjLyyvd8uvXr2fIa16+fJlGjRrh4+PD66+/TsWKFcmVKxd///03zzzzDNeuXburdj08POjatSvvvPMO//zzD/nz52fRokUUK1aMxx9/3Frv9OnTrF27Nt0pkFuH0dPSu3dvOnfuzJo1a2jXrh0LFy4kd+7ctG/fHoDk5GRCQ0M5deoUY8aMoXr16vj5+ZGcnEz9+vXTPEd77kRytO9y5cqFj4+PTZm3t7fN7/Ls2bMUL14cN7f0/811+vRpDMMgICAgzcfLlSuX7nMvXryIYRhpnl/KF+P58+fTff6dDB06lC5duuDm5kb+/PkpW7ZsmksHOHKnV6FChVKVeXt72/Tv2bNnKVWq1N0FjfnlnFZZSl/czXvodhz9PEmJI73f261f+Ld+ZoD5uZHeZ0xanye39omHhweFChWyxuJoTPb8Hk+fPs3hw4ft/jywp830lC9fnm+++YapU6cycOBArly5Qrly5RgyZAhDhw694/NzEiVAOZy7uzvNmjVj/fr1nDhxwq5bab29vblx40aq8nv5gklLypfqra9lT/KwefNmTp06xZYtW6wjF0CGrJnRs2dP3nzzTZYtW0aHDh1Ys2YNw4YNw93d3VqncOHC1KhRgzfeeCPNNm7+12p6nnnmGQoUKMCCBQto0qQJ69ato1u3btYRjt9++42ff/6ZRYsW0b17d+vzUq5PSYs96/1kRt/5+/uzfft2kpOT002CChcujMViYdu2bXh7e6d6PK2yFAUKFMDNzS3N62JSrgMpXLjwXUYPJUuWpE6dOnesl9HrKfn7+3PixIm7fn5sbGyaZRUqVADu7j10O45+nqR80cfExKSqe+rUqXv6naUnNjaWEiVKWI8TExM5f/68NZbMiKlw4cL4+vqyYMGCdB/PSI0aNaJRo0YkJSWxe/du3nnnHYYNG0ZAQMBt1xjLaTQFJoSHh2MYBs8//3yaF8klJCSwdu1a63GZMmX45ZdfbOps3ryZy5cvZ2hcZcqUAUj1WmvWrLnjc1O+iG790pw3b16quil17P3XbpUqVXj44YdZuHAhS5Ys4caNG/Ts2dOmTuvWrfntt98oX748derUSfVjTwLk4+NDp06d2LhxI1OmTCEhIcFmCsmRc3REZrTbokULrl+/zqJFi9Kt07p1awzD4OTJk2n2WfXq1dN9rp+fHw8//DArV660+T0mJyfz6aefUrJkSSpWrHjX8btKixYt+OOPP9i8efNdPX/x4sU2x1FRUfz11188+uijQOb8rh35PHnssccAbC4YBvjxxx85ePAgzZo1u+s40nNrn3z22WckJiZa+yQzYmrdujVHjhyhUKFCab63Uz7rHGHP55a7uzsPP/wws2fPBuCnn35y+HWyM40AifUOkAEDBhAUFMQLL7zAgw8+SEJCAnv37mX+/PlUq1bNep1H165dGTNmDK+99hpNmjThwIEDvPvuu+TLly9D4ypatCjNmzdn0qRJFChQgNKlS7Np0ybrXTy3ExwcTIECBejfvz9jx47F09OTxYsXp7qrCrB+sU6ZMoUWLVrg7u5OjRo1rMPoaenVqxf9+vXj1KlTBAcHp1pIb8KECURGRhIcHMyQIUOoVKkS169f5/jx40RERPDee+/ZNdrWu3dvZs+ezYwZM6hcuTLBwcHWxypXrkz58uUZNWoUhmFQsGBB1q5dS2Rk5B3bvR1H+s5eHTt2ZOHChfTv359Dhw7RtGlTkpOT+f7776lSpQrPPfccDRs2pG/fvvTs2ZPdu3fTuHFj/Pz8iImJYfv27VSvXp0XXngh3deYNGkSISEhNG3alBdffBEvLy/mzJnDb7/9xtKlS7PkatfDhg1j+fLlPPnkk4waNYp69epx7do1tm7dSuvWrWnatOltn79792769OnDf/7zH/7++29effVVSpQowYABA4DMeQ858nlSqVIl+vbtyzvvvIObmxstWrTg+PHjjBkzhsDAQIYPH37XcaRn5cqVeHh4EBISwv79+xkzZgw1a9a0Ti1nRkzDhg3jiy++oHHjxgwfPpwaNWqQnJxMdHQ0GzduZMSIETz88MMOtZnyufXWW2/RvXt3PD09qVSpEosXL2bz5s20atWKUqVKcf36devI091eS5ZtufACbLnP7Nu3z+jevbtRqlQpw8vLy/Dz8zNq165tvPbaazbrZNy4ccMYOXKkERgYaPj6+hpNmjQx9u3bl+5dYLfe+ZByN8at64ykrClzs5iYGKNdu3ZGwYIFjXz58hldunQxdu/ebdddYCnrheTKlcvw9/c3+vTpY/z000+pnnvjxg2jT58+hr+/v2GxWNJdB+hm//77r+Hr63vbO5vOnj1rDBkyxChbtqzh6elpFCxY0AgKCjJeffXVVGt/3E7t2rUNwJg6dWqqxw4cOGCEhIQYefLkMQoUKGD85z//MaKjo1PdFZRen9/82M3s7bu0fmfptXnt2jXjtddeMx544AHDy8vLKFSokPHYY48ZUVFRNvUWLFhgPPzww4afn5/h6+trlC9f3ujWrZvN3T/pSVkHKOW59evXt1k/xTDu7i6wO9VN771+82NprQN0q+7du6dal+jixYvG0KFDjVKlShmenp5GkSJFjFatWhm///67tc6tv++b1wHq2rWrkT9/fsPX19do2bKl8eeff9q0b+97yN51gFLY+3mSsuZOxYoVDU9PT6Nw4cJGly5d0l1z51alS5c2WrVqlaqc/19PJ8XNa2G1adPGyJ07t5EnTx6jY8eOxunTp22ee68xpfV7vHz5sjF69Gjr2kL58uUzqlevbgwfPtyIjY1NN+6bz/PWz6Lw8HCjePHihpubm/WO2Z07dxpPP/20Ubp0acPb29soVKiQ0aRJE2PNmjWp2szpLIZxywIEIiKSpS1atIiePXvy448/2nXtUk4wbtw4xo8fz9mzZzPl2iLJenQNkIiIiOQ4SoBEREQkx9EUmIiIiOQ4GgESERGRHEcJkIiIiOQ4SoBEREQkx9FCiGlITk7m1KlT5MmTJ0suniYiIpITGYbBpUuX7rj3ICgBStOpU6cIDAx0dRgiIiJyF/7+++87rravBCgNefLkAcwOzJs3b4a2nZCQwMaNGwkNDU13Z2C5d+pn51A/O4f62XnU186RWf0cFxdHYGCg9Xv8dpQApSFl2itv3ryZkgDlypWLvHnz6o8rE6mfnUP97BzqZ+dRXztHZvezPZev6CJoERERyXGUAImIiEiOowRIREREchwlQCIiIpLjKAESERGRHEcJkIiIiOQ4SoBEREQkx1ECJCIiIjmOEiARERHJcZQAiYiIiNMkJcHWrRa++64EW7daSEpyTRxKgERERMQpVq6EMmUgJMSDGTPqEBLiQZkyZrmzKQESERGRTLdyJbRrBydO2JafPGmWOzsJUgIkIiIimSopCYYOBcNI/VhK2bBhOHU6TAmQiIiIZKpt21KP/NzMMODvv816zqIESERERDJVTEzG1ssISoBEREQkU505Y1+9YsUyN46bKQESERGRTJGUBK+/DsOH376exQKBgdCokXPiAiVAIiIikglOn4YnnoAxY8xrfJo0MRMdi8W2XsrxrFng7u68+JQAiYiISIbavBlq1YJvvgFfX1i4ELZsgRUroEQJ27olS5rlzzzj3BhdngDNmTOHsmXL4uPjQ1BQENtucwn49u3badiwIYUKFcLX15fKlSszc+bMVPVmzZpFpUqV8PX1JTAwkOHDh3P9+vXMPA0REZEcLykJxo6F5s0hNhYefBB274YePczHn3kGjh+HyMhEwsJ2ExmZyLFjzk9+ADyc/5L/s3z5coYNG8acOXNo2LAh8+bNo0WLFhw4cIBSpUqlqu/n58egQYOoUaMGfn5+bN++nX79+uHn50ffvn0BWLx4MaNGjWLBggUEBwfzxx9/0OP/ez6tZElERETu3alT0LmzOdID0KsXvPMO5MplW8/dHZo0Mbhy5SRNmtR06rTXzVyaAM2YMYPevXvTp08fwBy52bBhA3PnzmXSpEmp6teuXZvatWtbj8uUKcPKlSvZtm2bNQHauXMnDRs2pFOnTtY6HTt25IcffnDCGYmIiOQ8GzdCly5w9iz4+cF775nH9zOXJUDx8fHs2bOHUaNG2ZSHhoYSFRVlVxt79+4lKiqK119/3Vr2yCOP8Omnn/LDDz9Qr149jh49SkREBN27d0+3nRs3bnDjxg3rcVxcHAAJCQkkJCQ4clp3lNJeRrcrttTPzqF+dg71s/Oorx2TmAjjx7sxdaobhmGhenWDJUsSqVQJbteFmdXPjrTnsgTo3LlzJCUlERAQYFMeEBBAbGzsbZ9bsmRJzp49S2JiIuPGjbOOIAE899xznD17lkceeQTDMEhMTOSFF15IlWjdbNKkSYwfPz5V+caNG8l169hdBomMjMyUdsWW+tk51M/OoX52HvX1nZ0758P06XU4eLAQAE88cYyePX/jyJFkjhyxr42M7uerV6/aXdelU2AAllvuhzMMI1XZrbZt28bly5fZtWsXo0aNokKFCnTs2BGALVu28MYbbzBnzhwefvhhDh8+zNChQylWrBhjxoxJs73w8HDCwsKsx3FxcQQGBhIaGkrevHnv8QxtJSQkEBkZSUhICJ6enhnatvyP+tk51M/OoX52HvW1fdavt/Dyy+6cP28hTx6DuXOTaN++JFDSrudnVj+nzODYw2UJUOHChXF3d0812nPmzJlUo0K3Klu2LADVq1fn9OnTjBs3zpoAjRkzhq5du1pHhapXr86VK1fo27cvr776Km5uqW988/b2xtvbO1W5p6dnpv0BZGbb8j/qZ+dQPzuH+tl51NdpS0iAV1+FN980jx96CJYvt1Chwt2lExndz4605bLb4L28vAgKCko1/BUZGUlwcLDd7RiGYXP9ztWrV1MlOe7u7hiGgZHWNrQiIiJyR3/9BY0b/y/5GTwYoqKgQgXXxnW3XDoFFhYWRteuXalTpw4NGjRg/vz5REdH079/f8Ccmjp58iQff/wxALNnz6ZUqVJUrlwZMNcFmjZtGoMHD7a22aZNG2bMmEHt2rWtU2Bjxoyhbdu2uLvqXjsREZEsbPVq6NkTLl6EfPlgwQLXrN2TkVyaAHXo0IHz588zYcIEYmJiqFatGhEREZQuXRqAmJgYoqOjrfWTk5MJDw/n2LFjeHh4UL58eSZPnky/fv2sdUaPHo3FYmH06NGcPHkSf39/2rRpwxtvvOH08xMREcnK4uNh5Eh46y3zuG5dWL4c/v9KlCzN5RdBDxgwgAEDBqT52KJFi2yOBw8ebDPakxYPDw/Gjh3L2LFjMypEERGRHOfoUejQwVzJGcwNTSdPBi8v18aVUVyeAImIiMj95YsvzJWc4+KgQAFYtAjatnV1VBnL5XuBiYiIyP3h+nUYNAjatTOTnwYNYN++7Jf8gBIgERERAf78E4KDYfZs83jkSNi6FdLYmjNb0BSYiIhIDrdsGfTtC5cuQeHC8PHH0KKFq6PKXBoBEhERyaGuXYN+/aBjRzP5adTInPLK7skPKAESERHJkX7/HR5+GObPB4sFRo+GzZuhRAlXR+YcmgITERHJYT75BF54Aa5cgSJF4NNPISTE1VE5l0aAREREcogrV8zb27t1M/+/aVNzyiunJT+gBEhERCRH2L8f6tWDhQvNKa9x4yAyEooVc3VkrqEpMBERkWzMMMykZ9Ag86LnokVhyRJz9CcnUwIkIiKSTV2+bF7r8+mn5nFIiPn/RYq4Nq77gabAREREsqFffoGgIDPhcXODN96Ar79W8pNCI0AiIiLZiGGYt7YPHQo3bpi3tS9daq7xI/+jBEhERCSbiIszV3Revtw8btkSPvrIXN1ZbGkKTEREJBv46Sdzymv5cvDwgKlTYe1aJT/p0QiQiIhIFmYY5gamI0ZAfLy5eemyZeZO7pI+JUAiIiJZ1D//QJ8+8MUX5nHbtuYt7wULujSsLEFTYCIiIlnQDz9A7dpm8uPpCTNnwpdfKvmxl0aAREREshDDgFmz4OWXISEBypY1r/upW9fVkWUtSoBERESyiAsXoGdPWLPGPH72WfjgA8if36VhZUmaAhMREckCdu6EWrXM5MfLC959Fz7/XMnP3VICJCIich9LTjZvaW/UCP7+GypUgF27YOBAc1NTuTuaAhMREblPnTsH3brB+vXm8XPPwbx5kDeva+PKDjQCJCIich/ats2c8lq/Hnx8zMRnyRIlPxlFCZCIiMh9JDnZ3Lj00Ufh5EmoVAm+/97c4kJTXhlHU2AiIiL3idOnoWtXiIw0j7t2hTlzIHdu18aVHSkBEhERuQ98+y106gSxseDra25v0aOHRn0yi6bAREREXCgpCcaPh+bNzeSnalX48UdzvR8lP5lHI0AiIiIuEhMDnTuboz8AvXrBO+9ArlyujSsnUAIkIiLiApGR0KULnDkDfn4wd655zY84h6bAREREnCgxEUaPhscfN5OfGjVg924lP86mESAREREnOXHCvNB52zbzuF8/cxd3X1/XxpUTKQESERFxgogIc1Xn8+chTx6YP99c2VlcQ1NgIiIimSghAUaOhFatzOSndm346SclP67m8gRozpw5lC1bFh8fH4KCgtiWMi6Yhu3bt9OwYUMKFSqEr68vlStXZubMmanq/fPPPwwcOJBixYrh4+NDlSpViIiIyMzTEBERSSU6Gpo0gTffNI8HDYKoKHNDU3Etl06BLV++nGHDhjFnzhwaNmzIvHnzaNGiBQcOHKBUqVKp6vv5+TFo0CBq1KiBn58f27dvp1+/fvj5+dG3b18A4uPjCQkJoUiRIqxYsYKSJUvy999/kydPHmefnoiI5GBr1pgLGV68CPnywYcfwrPPujoqSeHSBGjGjBn07t2bPn36ADBr1iw2bNjA3LlzmTRpUqr6tWvXpnbt2tbjMmXKsHLlSrZt22ZNgBYsWMCFCxeIiorC09MTgNKlSzvhbERERCA+HkaNMi9uBqhbF5Ytg3LlXBuX2HJZAhQfH8+ePXsYNWqUTXloaChRUVF2tbF3716ioqJ4/fXXrWVr1qyhQYMGDBw4kNWrV+Pv70+nTp14+eWXcXd3T7OdGzducOPGDetxXFwcAAkJCSQkJDh6areV0l5Gtyu21M/OoX52DvWz89xrXx87Bp07u7N7t3mFyZAhSUycmIyXl3ktkJgy6z3tSHsuS4DOnTtHUlISAQEBNuUBAQHExsbe9rklS5bk7NmzJCYmMm7cOOsIEsDRo0fZvHkznTt3JiIigj///JOBAweSmJjIa6+9lmZ7kyZNYvz48anKN27cSK5MWo4zMmWnO8lU6mfnUD87h/rZee6mr3fuLMY779Tm6lU3cueOZ8iQvdSrF8s332RCgNlERr+nr169anddl98Gb7lloxPDMFKV3Wrbtm1cvnyZXbt2MWrUKCpUqEDHjh0BSE5OpkiRIsyfPx93d3eCgoI4deoUb775ZroJUHh4OGFhYdbjuLg4AgMDCQ0NJW/evPd4hrYSEhKIjIwkJCTEOkUnGU/97BzqZ+dQPzvP3fT19eswapQbc+aYswz16yfzyScWSpd+KDNDzdIy6z2dMoNjD5clQIULF8bd3T3VaM+ZM2dSjQrdqmzZsgBUr16d06dPM27cOGsCVKxYMTw9PW2mu6pUqUJsbCzx8fF4eXmlas/b2xtvb+9U5Z6enpn2YZOZbcv/qJ+dQ/3sHOpn57G3rw8fhvbtYe9e83jkSHj9dTc8PV1+k3WWkNHvaUfactlvyMvLi6CgoFTDX5GRkQQHB9vdjmEYNtfvNGzYkMOHD5OcnGwt++OPPyhWrFiayY+IiMjdWL4cHnrITH4KFYKvvoIpU0A5atbg0hQ1LCyMDz74gAULFnDw4EGGDx9OdHQ0/fv3B8ypqW7dulnrz549m7Vr1/Lnn3/y559/snDhQqZNm0aXLl2sdV544QXOnz/P0KFD+eOPP/jqq6+YOHEiAwcOdPr5iYhI9nPtGvTvby5keOkSPPII7NsHLVu6OjJxhEuvAerQoQPnz59nwoQJxMTEUK1aNSIiIqy3rcfExBAdHW2tn5ycTHh4OMeOHcPDw4Py5cszefJk+vXrZ60TGBjIxo0bGT58ODVq1KBEiRIMHTqUl19+2ennJyIi2cuhQ+aU1y+/gMUCr7wC48aBh8uvqBVHufxXNmDAAAYMGJDmY4sWLbI5Hjx4MIMHD75jmw0aNGDXrl0ZEZ6IiAgAn35qjvxcuQL+/rB4MYSEuDoquVu6SktEROQ2rl6F3r2ha1cz+WnaFH7+WclPVqcESEREJB0HDpgrOS9YYE55jR0LkZFQrJirI5N75fIpMBERkfuNYcDChTBwoHnRc9Gi5pTXY4+5OjLJKEqAREREbnLtmju9ermzeLF5HBICn3wCd1iiTrIYJUAiIiL/75df4KWXmnDihBtubvDf/5obm7rpgpFsRwmQiIjkeIYB778PQ4d6cP16HkqUMFi61EKjRq6OTDKLEiAREcnR4uKgXz9YtgzAwkMPnWbduoIUK6YlnbMzJUAiIpJj7d1rLmx4+DC4u8PrrydRqdIuChfWss7ZnWY1RUQkxzEMmD0b6tc3k5/AQNi2DUaMSNb1PjmEfs0iIpKj/POPOeozaBDEx0PbtuZeXg0auDoycSYlQCIikmP8+KO5g/uKFeau7TNmwJdfQsGCro5MnE3XAImISLZnGPDWWzByJCQkQJkysHw51Kvn6sjEVZQAiYhItnbhAvTqBatXm8fPPAMffgj587s0LHExTYGJiEi2tWsX1K5tJj9eXvDuu+b0l5IfUQIkIiLZTnIyvPkmNGoE0dFQvjzs3Gnu7WWxuDo6uR9oCkxERLKVc+egRw/46ivzuEMHmD8f8uZ1aVhyn1ECJCIi2ca2bdCxI5w8Cd7e8Pbb8PzzGvWR1DQFJiIiWV5yMkycCE2bmslPxYrwww/Qt6+SH0mbRoBERCRLO3MGunaFjRvN4y5dYO5cyJ3btXHJ/U0JkIiIZFlbtkCnThATA76+5l1ePXtq1EfuTFNgIiKS5SQlwfjx0KyZmfxUrWqu8tyrl5IfsY9GgEREJEuJjYXOnWHzZvO4Z0945x3w83NtXJK1KAESEZEs45tvzOTnzBkz4Zk717z+R8RRmgITEZH7XmIijB4NoaFm8lO9OuzereRH7p5GgERE5L528qR5ofN335nHffvCrFnmRc8id0sJkIiI3LfWr4du3czVnXPnhvffh+eec3VUkh1oCkxERO47CQnw8svQsqWZ/NSuDT/9pORHMo5GgERE5L4SHW1uZxEVZR4PHAjTpoGPj2vjkuxFCZCIiNw31q6F7t3h4kVz89IPP4R27VwdlWRHmgITERGXi4+HESOgbVsz+alTB/buVfIjmUcjQCIi4lLHjpnX9vzwg3k8bBhMmQJeXi4NS7I5JUAiIuIyK1ea21f8+y/kzw+LFsGTT7o6KskJNAUmIiJOd+MGDB4Mzz5rJj/168O+fUp+xHmUAImIiFMdPgzBwebO7QAvvWQucli6tGvjkpzF5QnQnDlzKFu2LD4+PgQFBbFt27Z0627fvp2GDRtSqFAhfH19qVy5MjNnzky3/rJly7BYLDz11FOZELmIiDjqs8/goYfMNX0KFYJ162DqVPD0dHVkktO49Bqg5cuXM2zYMObMmUPDhg2ZN28eLVq04MCBA5QqVSpVfT8/PwYNGkSNGjXw8/Nj+/bt9OvXDz8/P/r27WtT96+//uLFF1+kUaNGzjodERFJx7VrEBYG771nHj/yCCxdCiVLujYuybnuegQoPj6eQ4cOkZiYeNcvPmPGDHr37k2fPn2oUqUKs2bNIjAwkLlz56ZZv3bt2nTs2JEHH3yQMmXK0KVLFx5//PFUo0ZJSUl07tyZ8ePHU65cubuOT0RE7t2hQ+Y1Pu+9BxYLvPIKfPutkh9xLYdHgK5evcrgwYP56KOPAPjjjz8oV64cQ4YMoXjx4owaNcquduLj49mzZ0+q+qGhoUSlLP95B3v37iUqKorXX3/dpnzChAn4+/vTu3fv206ppbhx4wY3btywHsfFxQGQkJBAQkKCXbHYK6W9jG5XbKmfnUP97BxZuZ+XLLEwcKA7V65Y8Pc3WLQoiZAQA8Mwt7u432Tlvs5KMqufHWnP4QQoPDycn3/+mS1btvDEE09Yy5s3b87YsWPtToDOnTtHUlISAQEBNuUBAQHExsbe9rklS5bk7NmzJCYmMm7cOPr06WN9bMeOHXz44Yfs27fP7nOaNGkS48ePT1W+ceNGcuXKZXc7joiMjMyUdsWW+tk51M/OkZX6+cYNd95/vzrffGNe2Vyt2lnCwn4iIeE6EREuDs4OWamvs7KM7uerV6/aXdfhBOjLL79k+fLl1K9fH4vFYi2vWrUqR44ccbQ5mzYADMNIVXarbdu2cfnyZXbt2sWoUaOoUKECHTt25NKlS3Tp0oX333+fwoUL2x1DeHg4YWFh1uO4uDgCAwMJDQ0lb968jp3QHSQkJBAZGUlISAieuuov06ifnUP97BxZrZ8PHIBOnTw4cMCCxWLw6qvJvPpqftzdH3N1aHeU1fo6q8qsfk6ZwbGHwwnQ2bNnKVKkSKryK1eu3DFxuVnhwoVxd3dPNdpz5syZVKNCtypbtiwA1atX5/Tp04wbN46OHTty5MgRjh8/Tps2bax1k5OTAfDw8ODQoUOUL18+VXve3t54e3unKvf09My0P4DMbFv+R/3sHOpn58gK/bxokbl56dWrULQoLF5s4bHH3AF3V4fmkKzQ19lBRvezI205fBF03bp1+eqrr6zHKUnP+++/T4MGDexux8vLi6CgoFTDX5GRkQQHB9vdjmEY1ut3KleuzK+//sq+ffusP23btqVp06bs27ePwMBAu9sVERH7Xb5sbmLas6eZ/DRvbi5s+Nj9P+gjOZTDI0CTJk3iiSee4MCBAyQmJvLWW2+xf/9+du7cydatWx1qKywsjK5du1KnTh0aNGjA/PnziY6Opn///oA5NXXy5Ek+/vhjAGbPnk2pUqWoXLkyYK4LNG3aNAYPHgyAj48P1apVs3mN/PnzA6QqFxGRjPHrr9C+Pfz+O7i5wYQJEB5u/r/I/crhBCg4OJgdO3Ywbdo0ypcvz8aNG3nooYfYuXMn1atXd6itDh06cP78eSZMmEBMTAzVqlUjIiKC0v+/HGhMTAzR0dHW+snJyYSHh3Ps2DE8PDwoX748kydPpl+/fo6ehoiI3CPDgA8+gCFD4Pp1KF7cXNuncWNXRyZyZ3e1EGL16tWtt8HfqwEDBjBgwIA0H1u0aJHN8eDBg62jPfa6tQ0REbl3ly5Bv35mwgPwxBPw8cfg7+/auETs5fAAZUREBBs2bEhVvmHDBtavX58hQYmIyP1r715zO4ulS8HdHaZMga++UvIjWYvDCdCoUaNISkpKVW4Yht1rAImISNZjGDBnDjRoYG5oGhhobmI6cqSu95Gsx+EpsD///JOqVaumKq9cuTKHDx/OkKBEROT+8u+/0KcPrFhhHrdpAwsXmhuaimRFDufs+fLl4+jRo6nKDx8+jJ+fX4YEJSIi94/du6F2bTP58fSEGTNg9WolP5K1OZwAtW3blmHDhtms+nz48GFGjBhB27ZtMzQ4ERFxHcOAt96C4GA4dgzKlIHt22H4cHNTU5GszOEE6M0338TPz4/KlStTtmxZypYtS5UqVShUqBDTpk3LjBhFRMTJLl6EZ56BYcPMTUufeca8+LlePVdHJpIxHL4GKF++fERFRREZGcnPP/+Mr68vNWrUoLEWfhARyRZ27YLnnoO//gIvL5g+3dzeQqM+kp3c1TpAFouF0NBQQkNDMzoeERFxkeRk8/qe8HBITITy5WH5cggKcnVkIhnvrhKgTZs2sWnTJs6cOWPdbDTFggULMiQwERFxnvPnzb28UrZ6bN8e3n8f8uZ1bVwimcXhBGj8+PFMmDCBOnXqUKxYMYd2gBcRkfvP9u3QsSOcOAHe3uaFz337aspLsjeHE6D33nuPRYsW0bVr18yIR0REnCQ52VzFecwYSEqCihXhs8+gZk1XRyaS+RxOgOLj4wkODs6MWERExEnOnIFu3SBlZ6POnWHuXMiTx7VxiTiLw7fB9+nThyVLlmRGLCIi4gRbt0KtWmby4+sLH34In3yi5EdyFodHgK5fv878+fP55ptvqFGjBp6enjaPz5gxI8OCExGRjJOUBG+8AePHm9NfVaqYU17Vqrk6MhHnczgB+uWXX6hVqxYAv/32m81juiBaROT+FBtrTnNt3mwe9+wJ77wD2sFIciqHE6Bvv/02M+IQEZFM8s030KULnD4NuXLBe++B7mORnM7ha4BERCRrSEw07/AKDTWTn+rVYc8eJT8icJcLIf744498/vnnREdHEx8fb/PYypUrMyQwERG5eydPQqdO8N135vHzz5vr+/j6ujYukfuFwyNAy5Yto2HDhhw4cIBVq1aRkJDAgQMH2Lx5M/ny5cuMGEVExAFff23e5fXdd5A7NyxZAvPnK/kRuZnDCdDEiROZOXMm69atw8vLi7feeouDBw/Svn17SpUqlRkxioiIHRISzH28WrSAc+fMJOinn8xVnkXElsMJ0JEjR2jVqhUA3t7eXLlyBYvFwvDhw5k/f36GBygiInf299/w6KMwebJ5PGAA7NwJDzzg0rBE7lsOJ0AFCxbk0qVLAJQoUcJ6K/w///zD1atXMzY6ERG5o3XrzNGeqChz89LPP4fZs8HHx9WRidy/HL4IulGjRkRGRlK9enXat2/P0KFD2bx5M5GRkTRr1iwzYhQRkTTEx5tTXinrz9apA8uXQ7lyro1LJCtwOAF69913uX79OgDh4eF4enqyfft2nnnmGcaMGZPhAYqISGrHj0OHDvDDD+bxsGHm9Je3tyujEsk6HE6AChYsaP1/Nzc3Ro4cyciRIzM0KBERSd+qVdCrF/zzD+TPD4sWwZNPujgokSzGrgQoLi6OvHnzWv//dlLqiYhIxrpxA0aMMLewAKhfH5Ytg9KlXRuXSFZkVwJUoEABYmJiKFKkCPnz509zzy/DMLBYLCQlJWV4kCIiOV1MTC6aNHHnp5/M4xdfhIkT4Zb9qEXETnYlQJs3b7ZOfWkvMBER51qxwsKIEY9y9aobhQrBRx/B/69GIiJ3ya4EqEmTJgAkJiayZcsWevXqRWBgYKYGJiKS012/DmFhMHeu+VEdHJzM8uVulCzp4sBEsgGH1gHy8PBg2rRpmuYSEclkf/xhXuMzd655/Oyzf/DNN0lKfkQyiMMLITZr1owtW7ZkQigiIgLm3l1BQfDzz+DvD+vWJdK160E87mr7ahFJi8N/Ti1atCA8PJzffvuNoKAg/Pz8bB5v27ZthgUnIpKTXL0KQ4fCBx+Yx48+CosXg7+/QUSES0MTyXYcToBeeOEFAGakLD16E90FJiJydw4ehPbt4bffwGKBMWPgtdfA3d3c5FREMpbDCVBycnJmxCEikmN99JG5eenVqxAQYE6BPfaYq6MSyd4cvgYoo82ZM4eyZcvi4+NDUFAQ27ZtS7fu9u3badiwIYUKFcLX15fKlSszc+ZMmzrvv/8+jRo1okCBAhQoUIDmzZvzQ8pa8SIi95ErV6B7d+jRw0x+mjc3r/tR8iOS+e7qkrorV66wdetWoqOjiY+Pt3lsyJAhdrezfPlyhg0bxpw5c2jYsCHz5s2jRYsWHDhwgFKlSqWq7+fnx6BBg6hRowZ+fn5s376dfv364efnR9++fQHYsmULHTt2JDg4GB8fH6ZOnUpoaCj79++nRIkSd3O6IiIZ7tdfzSmv338HNzcYP97c2NTd3dWRieQMDidAe/fupWXLlly9epUrV65QsGBBzp07R65cuShSpIhDCdCMGTPo3bs3ffr0AWDWrFls2LCBuXPnMmnSpFT1a9euTe3ata3HZcqUYeXKlWzbts2aAC1evNjmOe+//z4rVqxg06ZNdOvWzdHTFRHJUIYBH34Igweb6/wUL25Oef3/cmsi4iQOT4ENHz6cNm3acOHCBXx9fdm1axd//fUXQUFBTJs2ze524uPj2bNnD6GhoTbloaGhREVF2dXG3r17iYqKsi7UmJarV6+SkJBgs4mriIgrXLoEXbrA88+byc8TT8C+fUp+RFzB4RGgffv2MW/ePNzd3XF3d+fGjRuUK1eOqVOn0r17d5555hm72jl37hxJSUkEBATYlAcEBBAbG3vb55YsWZKzZ8+SmJjIuHHjrCNIaRk1ahQlSpSgefPm6da5ceMGN27csB6nbPiakJBAQgbffpHSXka3K7bUz86hfrbfvn3QqZMHhw9bcHc3mDAhmREjknFzu/NdXupn51FfO0dm9bMj7TmcAHl6elo3Qw0ICCA6OpoqVaqQL18+oqOjHW0u1caqKZuq3s62bdu4fPkyu3btYtSoUVSoUIGOHTumqjd16lSWLl3Kli1b8PHxSbe9SZMmMX78+FTlGzduJFeuXHaeiWMiIyMzpV2xpX52DvVz+gwDvv66DAsWVCMhwUKhQtd48cXdVKlyga+/dqwt9bPzqK+dI6P7+erVq3bXdTgBql27Nrt376ZixYo0bdqU1157jXPnzvHJJ59QvXp1u9spXLgw7u7uqUZ7zpw5k2pU6FZly5YFoHr16pw+fZpx48alSoCmTZvGxIkT+eabb6hRo8Zt2wsPDycsLMx6HBcXR2BgIKGhoeTNm9fuc7JHQkICkZGRhISE4KltnDON+tk51M+39++/0L+/O198YV5t0LJlMh9+6EGhQvUdakf97Dzqa+fIrH5OmcGxh90JUGJiIh4eHkycOJFLly4B8N///pfu3bvzwgsvUKFCBRYuXGj3C3t5eREUFERkZCRPP/20tTwyMpInn3zS7nYMw7CZvgJ48803ef3119mwYQN16tS5Yxve3t54e3unKvf09My0P4DMbFv+R/3sHOrn1Hbvhg4d4OhR8PCAKVNg+HA3LJa7X31E/ew86mvnyOh+dqQtuxOgYsWK0b17d3r16mVNKvz9/Ym4h/XZw8LC6Nq1K3Xq1KFBgwbMnz+f6Oho+vfvD5gjMydPnuTjjz8GYPbs2ZQqVYrKlSsD5rpA06ZNY/DgwdY2p06dypgxY1iyZAllypSxjjDlzp2b3Llz33WsIiL2MAx45x148UXz2p7SpWH5cnj4YVdHJiI3szsBCgsLY9GiRcycOZN69erRp08fOnTocE9JRYcOHTh//jwTJkwgJiaGatWqERERQenSpQGIiYmxua4oOTmZ8PBwjh07hoeHB+XLl2fy5Mn069fPWmfOnDnEx8fTrl07m9caO3Ys48aNu+tYRUTu5OJF6N0bVq0yj59+2rzlvUAB18YlIqnZnQCFh4cTHh7Otm3bWLBgAcOGDWPYsGG0a9eOPn360LBhw7sKYMCAAQwYMCDNxxYtWmRzPHjwYJvRnrQcP378ruIQEbkX339vTnn99Rd4ecG0aTBokLmvl4jcfxyejG7UqBELFy4kNjaWWbNmcfjwYRo1akSlSpWYOnVqZsQoInLfMgyYPh0eecRMfsqVg6goc6FDJT8i96+7vhrPz8+P3r17s23bNtauXcu5c+cIDw/PyNhERO5r589D27bm9T6JiebWFj/9BEFBro5MRO7krhOgq1evsnDhQho3bkzbtm0pVKgQb7zxRkbGJiJy39qxA2rVgnXrwNsb5s6FZcsgXz5XRyYi9nB4HaBt27axcOFCVqxYQVJSEu3ateP111+ncePGmRGfiMh9JTkZpk6F0aMhKQkeeAA++8xMhkQk67A7AZo4cSKLFi3iyJEj1KlThzfffJOOHTtm+EKBIiL3q7NnoVs3rCs4d+oE770HefK4Ni4RcZzdCdDMmTPp0qULvXv3plq1apkZk4jIfWfrVjPhOXUKfH3NtX569dKFziJZld0J0KlTp7QqpojkOElJMHEijBtnTn9VqWJOeenfgSJZm90JkJIfEclpYmOhSxfYtMk87tED3n0X/PxcGpaIZACHL4IWEckJNm2Czp3h9GnIlcu8y6tbN1dHJSIZ5e535RMRyYaSkmDsWAgJMZOfatXMjU2V/IhkLxoBEhH5f6dOmRc6b91qHj//PLz1lnnRs4hkL3c1AnTkyBFGjx5Nx44dOXPmDABff/01+/fvz9DgREScZcMGqFnTTH5y54bFi2H+fCU/ItmVwwnQ1q1bqV69Ot9//z0rV67k8uXLAPzyyy+MHTs2wwMUEclMiYkQHg5PPAHnzplJ0J495kiQiGRfDidAo0aN4vXXXycyMhIvLy9redOmTdm5c2eGBicikpn+/hsefRQmTzaPBwyAXbugYkWXhiUiTuBwAvTrr7/y9NNPpyr39/fn/PnzGRKUiEhm++orc/uKHTsgb15zbZ/Zs8HHx9WRiYgzOJwA5c+fn5iYmFTle/fupUSJEhkSlIhIZklIMHdvb90aLlwwd27/6Sf4z39cHZmIOJPDCVCnTp14+eWXiY2NxWKxkJyczI4dO3jxxRfppvtEReQ+dvw4NGoE06ebx0OHmiNA5cu7NCwRcQGHE6A33niDUqVKUaJECS5fvkzVqlVp3LgxwcHBjB49OjNiFBG5Z19+CbVrw/ffQ/78sGoVzJoF3t4uDkxEXMLhdYA8PT1ZvHgxEyZMYO/evSQnJ1O7dm0eeOCBzIhPROSe3LgBL79srucD8PDDsGwZlCnj0rBExMUcToC2bt1KkyZNKF++POU1biwi97GjR6F9e/O2doARI8yNTW+6gVVEciiHp8BCQkIoVaoUo0aN4rfffsuMmERE7tmKFeaU1549ULAgrF0L06Yp+RERk8MJ0KlTpxg5ciTbtm2jRo0a1KhRg6lTp3LixInMiE9ExCHXr5vr+fznPxAXBw0bwr595l1fIiIpHE6AChcuzKBBg9ixYwdHjhyhQ4cOfPzxx5QpU4bHHnssM2IUEbHLn39Cgwbmzu1grvD87bcQGOjauETk/nNPm6GWLVuWUaNGUbNmTcaMGcPWlB0ERUScbOlS6NsXLl8Gf3/45BN4/HFXRyUi96u72gwVYMeOHQwYMIBixYrRqVMnHnzwQdatW5eRsYmI3NG1a+au7Z06mclPkybmlJeSHxG5HYdHgF555RWWLl3KqVOnaN68ObNmzeKpp54iV65cmRGfiEi6Dh407/L67TewWGDMGPPH457GtkUkJ3D4Y2LLli28+OKLdOjQgcKFC2dGTCIid/Txx/DCC3D1KgQEwOLF0KyZq6MSkazC4QQoKioqM+IQEbHLlSswaBAsWmQeN2sGn34KRYu6NCwRyWLsSoDWrFlDixYt8PT0ZM2aNbet27Zt2wwJTETkVr/9Zk55HTwIbm4wbhy88gq4u7s6MhHJauxKgJ566iliY2MpUqQITz31VLr1LBYLSUlJGRWbiAgAhgELFsDgweZFz8WLw5Il5gXPIiJ3w64EKDk5Oc3/FxHJbJcumdf6LF5sHj/+uHmLu7+/a+MSkazN4dvgP/74Y27cuJGqPD4+no8//jhDghIRAfj5Z6hTx0x+3N1h0iSIiFDyIyL3zuEEqGfPnvz777+pyi9dukTPnj0zJCgRydkMA957z9y5/Y8/oGRJ2LoVRo0yr/0REblXDt8FZhgGFoslVfmJEyfIly9fhgQlIjnXv/+aKzp/9pl53Lq1ecdXoUIuDUtEshm7/y1Vu3ZtHnroISwWC82aNeOhhx6y/tSsWZNGjRrRvHlzhwOYM2cOZcuWxcfHh6CgILZt25Zu3e3bt9OwYUMKFSqEr68vlStXZubMmanqffHFF1StWhVvb2+qVq3KqlWrHI5LRJxvzx4ICjKTHw8PmD4d1qxR8iMiGc/uEaCUu7/27dvH448/Tu7cua2PeXl5UaZMGZ599lmHXnz58uUMGzaMOXPm0LBhQ+bNm0eLFi04cOAApUqVSlXfz8+PQYMGUaNGDfz8/Ni+fTv9+vXDz8+Pvn37ArBz5046dOjAf//7X55++mlWrVpF+/bt2b59Ow8//LBD8YmIcxgGvPsuvPgixMdD6dKwfLk5BSYikhnsToDGjh0LQJkyZejQoQM+Pj73/OIzZsygd+/e9OnTB4BZs2axYcMG5s6dy6RJk1LVr127NrVr17YelylThpUrV7Jt2zZrAjRr1ixCQkIIDw8HIDw8nK1btzJr1iyWLl16zzGLSMa6eBF694aUgdqnnjJveS9QwKVhiUg25/DlhN27d8+Q5Cc+Pp49e/YQGhpqUx4aGmr3atN79+4lKiqKJjctBrJz585UbT7++ONawVrkPvTDD/DQQ2by4+kJb70FK1cq+RGRzOfwRdBJSUnMnDmTzz77jOjoaOLj420ev3Dhgl3tnDt3jqSkJAICAmzKAwICiI2Nve1zS5YsydmzZ0lMTGTcuHHWESSA2NhYh9u8ceOGza39cXFxACQkJJCQkGDX+dgrpb2MbldsqZ+d42772TDgrbfceOUVNxITLZQrZ7B4cRJBQQaJiZkRadam97PzqK+dI7P62ZH2HE6Axo8fzwcffEBYWBhjxozh1Vdf5fjx43z55Ze89tprjjaX6o6y9O4yu9m2bdu4fPkyu3btYtSoUVSoUIGOHTvedZuTJk1i/Pjxqco3btyYabvcR0ZGZkq7Ykv97ByO9POlS568/XZtfvyxGADBwScZOHAfp08nEhGRWRFmD3o/O4/62jkyup+vXr1qd12HE6DFixfz/vvv06pVK8aPH0/Hjh0pX748NWrUYNeuXQwZMsSudgoXLoy7u3uqkZkzZ86kGsG5VdmyZQGoXr06p0+fZty4cdYEqGjRog63GR4eTlhYmPU4Li6OwMBAQkNDyZs3r13nY6+EhAQiIyMJCQnB09MzQ9uW/1E/O4ej/bxzp4XBg935+28L3t4G06Yl07dvESyW0Ds+NyfT+9l51NfOkVn9nDKDYw+HE6DY2FiqV68OQO7cua2LIrZu3ZoxY8bY3Y6XlxdBQUFERkby9NNPW8sjIyN58skn7W7HMAyb6asGDRoQGRnJ8OHDrWUbN24kODg43Ta8vb3x9vZOVe7p6ZlpfwCZ2bb8j/rZOe7Uz8nJ8Oab8OqrkJQEDzwAn31moVYtd0A7mdpL72fnUV87R0b3syNtOZwAlSxZkpiYGEqVKkWFChXYuHEjDz30ED/++GOaScTthIWF0bVrV+rUqUODBg2YP38+0dHR9O/fHzBHZk6ePGndYmP27NmUKlWKypUrA+a6QNOmTWPw4MHWNocOHUrjxo2ZMmUKTz75JKtXr+abb75h+/btjp6qiGSAs2ehWzf4+mvzuFMnc5XnPHlcG5eI5GwOJ0BPP/00mzZt4uGHH2bo0KF07NiRDz/8kOjoaJtRF3t06NCB8+fPM2HCBGJiYqhWrRoRERGULl0agJiYGKKjo631k5OTCQ8P59ixY3h4eFC+fHkmT55Mv379rHWCg4NZtmwZo0ePZsyYMZQvX57ly5drDSARF/juO+jYEU6dAh8fc62fXr3gDpf5iYhkOocToMmTJ1v/v127dpQsWZKoqCgqVKhA27ZtHQ5gwIABDBgwIM3HFi1aZHM8ePBgm9Ge9LRr14527do5HIuIZIykJHPj0rFjzemvypXh88+hWjVXRyYiYnI4AbpV/fr1qV+/fkbEIiLZwOnT0KULfPONedy9O8yeDX5+ro1LRORmdiVAa9assbvBuxkFEpHsYfNm8xqf06chVy6YM8dMgERE7jd2JUAp+4DdicViISkp6V7iEZEsKCkJXn8d/vtfc5HDatXMvbyqVnV1ZCIiabMrAUpOTs7sOEQki7pwwYcnnnBn61bzuE8fc0uLTFpDVEQkQ9zzNUAiknNFRloYPvxR/v3Xjdy5Yd48cwpMROR+53ACNGHChNs+fjfbYYhI1pKYCK+9BpMmeQAe1Khh8PnnFipWdHVkIiL2cTgBWrVqlc1xQkKCzbo8SoBEsrcTJ8y1fVLWFn3iiWN89llJ8uTRqrkiknU4nADt3bs3VVlcXBw9evSw2dJCRLKfr74y7+o6fx7y5oW5cxPx8/sFH5+Srg5NRMQhbhnRSN68eZkwYYJDe4GJSNaRkAAvvQStW5vJT1AQ/PQT/Oc/hqtDExG5KxmSAAH8888/1o1RRST7+OsvaNwYpk0zj4cMgR07oHx518YlInIvHJ4Ce/vtt22ODcMgJiaGTz75hCeeeCLDAhMR11u9Gnr0gH/+gfz5YcEC0Ey3iGQHDidAM2fOtDl2c3PD39+f7t27Ex4enmGBiYjrxMfDyJHmej4A9eqZCxuWKePSsEREMozDCdCxY8cyIw4RuU8cPQodOsDu3ebxiBEwcSJ4ebk2LhGRjKSFEEXEasUK6N0b4uKgYEFYtAjatHF1VCIiGc/hBOj69eu88847fPvtt5w5cybVNhk//fRThgUnIs5x/bo50jNnjnkcHAzLlkFgoGvjEhHJLA4nQL169SIyMpJ27dpRr149LBZLZsQlIk7y55/mlFfKEl+jRsGECeCpdQ1FJBtzOAH66quviIiIoGHDhpkRj4g40bJl8PzzcPkyFC4Mn3wCuplTRHICh9cBKlGiBHny5MmMWETESa5dg379zC0tLl821/nZt0/Jj4jkHA4nQNOnT+fll1/mr7/+yox4RCST/f47PPwwzJ8PFguMGQObNkGJEq6OTETEeRyeAqtTpw7Xr1+nXLly5MqVC89bLhS4cOFChgUnIhnr44/hhRfg6lUICIBPP4XmzV0dlYiI8zmcAHXs2JGTJ08yceJEAgICdBG0SBZw5QoMGmTe1g7w2GOweDEULerSsEREXMbhBCgqKoqdO3dSs2bNzIhHRDLY/v3Qvj0cOABubjBuHLzyCri7uzoyERHXcTgBqly5MteuXcuMWEQkAxkGLFxojvxcuwbFisGSJfDoo66OTETE9Ry+CHry5MmMGDGCLVu2cP78eeLi4mx+RMT1Ll+Grl3NVZ2vXYPQUPMuLyU/IiImh0eAUnZ8b9asmU25YRhYLBaSkpIyJjIRuSs//2xOef3xhznN9frr5sambg7/c0dEJPtyOAH69ttvMyMOEblHhmHe2j50KNy4ASVLwtKl8Mgjro5MROT+43AC1KRJk8yIQ0TuQVwc9O0Ly5ebx61awUcfQaFCro1LROR+5XAC9N1339328caNG991MCLiuJ9+Mqe8jhwBDw+YPBmGD9eUl4jI7TicAD2axlWUN68FpGuARJzDMGD2bHMX9/h4KF3a3Nurfn1XRyYicv9z+N+IFy9etPk5c+YMX3/9NXXr1mXjxo2ZEaOI3OKff6BdOxg82Ex+nnrK3M1dyY+IiH0cHgHKly9fqrKQkBC8vb0ZPnw4e/bsyZDARCRtP/wAHTrA8ePg6QnTppmJkBZlFxGxX4ZdJeDv78+hQ4cyqjkRuYVhwMyZ5l1dx49DuXIQFQVDhij5ERFxlMMjQL/88ovNsWEYxMTEMHnyZG2PIZJJLlyAHj1g7VrzuF07+OADSGNAVkRE7OBwAlSrVi0sFguGYdiU169fnwULFmRYYCJiioqC556Dv/8Gb29zFKh/f436iIjcC4cToGPHjtkcu7m54e/vj4+PT4YFJSKQnGxe3/PKK5CUBA88AJ99BrVquToyEZGsz+FrgEqXLm3zExgYeE/Jz5w5cyhbtiw+Pj4EBQWxbdu2dOuuXLmSkJAQ/P39yZs3Lw0aNGDDhg2p6s2aNYtKlSrh6+tLYGAgw4cP5/r163cdo4iznT0LrVvDyy+byU/HjrBnj5IfEZGMYncCtHnzZqpWrZrmhqf//vsvDz744G2Tl7QsX76cYcOG8eqrr7J3714aNWpEixYtiI6OTrP+d999R0hICBEREezZs4emTZvSpk0b9u7da62zePFiRo0axdixYzl48CAffvghy5cvJzw83KHYRFxl2zYz0Vm/Hnx84P33YfFiyJPH1ZGJiGQfdidAs2bN4vnnnydv3rypHsuXLx/9+vVjxowZDr34jBkz6N27N3369KFKlSrMmjWLwMBA5s6dm24MI0eOpG7dujzwwANMnDiRBx54gLUpV4YCO3fupGHDhnTq1IkyZcoQGhpKx44d2b17t0OxiThbcjK88Ya5Y/upU1C5snnLe58+ut5HRCSj2X0N0M8//8yUKVPSfTw0NJRp06bZ/cLx8fHs2bOHUaNGpWonKirKrjaSk5O5dOkSBQsWtJY98sgjfPrpp/zwww/Uq1ePo0ePEhERQffu3dNt58aNG9y4ccN6nDLKlZCQQEJCgt3nZI+U9jK6XbGV1fr59Gno2dOdb74x/03SpUsyb7+dRO7ccD+fQlbr56xK/ew86mvnyKx+dqQ9uxOg06dP4+npmX5DHh6cPXvW7hc+d+4cSUlJBAQE2JQHBAQQGxtrVxvTp0/nypUrtG/f3lr23HPPcfbsWR555BEMwyAxMZEXXnghVaJ1s0mTJjF+/PhU5Rs3biRXrlx2npFjIiMjM6VdsZUV+vmXXwozc2YQFy964u2dSN++v9Cs2d/cYdu9+0pW6OfsQP3sPOpr58jofr569ardde1OgEqUKMGvv/5KhQoV0nz8l19+oVixYna/cArLLWP7hmGkKkvL0qVLGTduHKtXr6ZIkSLW8i1btvDGG28wZ84cHn74YQ4fPszQoUMpVqwYY8aMSbOt8PBwwsLCrMdxcXEEBgYSGhqa5pTfvUhISCAyMpKQkJDbJpRyb7JCPyclwRtvuPHGG24YhoWqVQ2WLDGoWrU6UN3V4dklK/RzdqB+dh71tXNkVj+ndZ1yeuxOgFq2bMlrr71GixYtUt31de3aNcaOHUvr1q3tfuHChQvj7u6earTnzJkzqUaFbrV8+XJ69+7N559/TvPmzW0eGzNmDF27dqVPnz4AVK9enStXrtC3b19effVV3NLYItvb2xtvb+9U5Z6enpn2B5CZbcv/3K/9HBMDnTrBli3mce/e8PbbFnLluv9itcf92s/ZjfrZedTXzpHR/exIW3ZfBD169GguXLhAxYoVmTp1KqtXr2bNmjVMmTKFSpUqceHCBV599VW7X9jLy4ugoKBUw1+RkZEEBwen+7ylS5fSo0cPlixZQqtWrVI9fvXq1VRJjru7O4ZhpFq8UcQVNm6EmjXN5MfPDz791FzVOZNmW0VEJA12jwAFBAQQFRXFCy+8QHh4uDWZsFgsPP7448yZM+eOIze3CgsLo2vXrtSpU4cGDRowf/58oqOj6d+/P2BOTZ08eZKPP/4YMJOfbt268dZbb1G/fn3r6JGvr691k9Y2bdowY8YMateubZ0CGzNmDG3btsXd3d2h+EQyUmIijB0LkyaZ+3rVrGkubFixoqsjExHJeRxaCbp06dJERERw8eJFDh8+jGEYPPDAAxQoUOCuXrxDhw6cP3+eCRMmEBMTQ7Vq1YiIiKB06dIAxMTE2KwJNG/ePBITExk4cCADBw60lnfv3p1FixYB5kiVxWJh9OjRnDx5En9/f9q0acMbb7xxVzGKZIQTJ8wpr5Slsvr3N7e00ALqIiKu4fBWGAAFChSgbt26GRLAgAEDGDBgQJqPpSQ1KbakXDBxGx4eHowdO5axY8dmQHQi9y4iArp1g/PnzcUMP/gAbrpxUUREXMDhrTBExD4JCTByJLRqZSY/Dz0Ee/cq+RERuR/c1QiQiNxedLS5g/vOnebx4MHw5pvmbu4iIuJ6SoBEMtiaNdCjB1y8CPnywYIF8Mwzro5KRERupikwkQwSHw/Dh8OTT5rJT7165pSXkh8RkfuPEiCRDHDsGDzyCMyaZR6HhZl3fJUt69KwREQkHZoCE7lHX3xhruT8779QoAB89BG0aePqqERE5HY0AiRyl65fh0GDoF07M/kJDoZ9+5T8iIhkBUqARO7C4cNmwjN7tnn88svm1halSrk0LBERsZOmwEQctGwZ9O0Lly5B4cLwySfwxBOujkpERByhESARO127Bv36QceOZvLTuLE55aXkR0Qk61ECJGKHQ4egfn2YPx8sFhg9GjZtghIlXB2ZiIjcDU2BidzBp5+am5deuQJFisDixdC8uaujEhGRe6ERIJF0XL0KvXpB165m8vPYY+aUl5IfEZGsTwmQSBr274e6dWHhQnBzg/HjYeNGKFbM1ZGJiEhG0BSYyE0MAxYtgoEDzYueixWDJUvg0UddHZmIiGQkJUAi/+/yZXjhBfOaH4DQUPMW9yJFXBuXiIhkPE2BiQC//AJ16pjJj7s7TJwI69cr+RERya40AiQ5mmHA++/DkCFw44Z5W/uyZebGpiIikn0pAZIcKy7OXNhw2TLzuFUr8/qfwoVdGpaIiDiBpsAkR9q7F4KCzOTHwwPefBPWrFHyIyKSU2gESHIUw4A5cyAsDOLjzc1Lly83V3kWEZGcQwmQ5Bj//AN9+sAXX5jHTz4JCxZAwYIuDUtERFxAU2CSI/z4Izz0kJn8eHrCrFmwapWSHxGRnEoJkGRrhmEmOw0bwrFjULYs7NgBQ4eam5qKiEjOpCkwybYuXfLk2WfdWbfOPG7XDj74APLlc21cIiLiekqAJFvatctCWNijnD3rhpcXzJxprvKsUR8REQFNgUk2k5xs3tL+2GPunD2biwoVDHbtggEDlPyIiMj/aARIso1z56B7d4iIALDQqNEJvvwygIIFPV0dmoiI3GeUAEm2sG0bdOwIJ0+Cjw/MnJlI0aJ7yJOnpatDExGR+5CmwCRLS042Ny5t2tRMfipVgu+/h969DU15iYhIujQCJFnWmTPQpQtERprHXbuaqzznzg0JCa6NTURE7m9KgCRL+vZb6NQJYmPB19dMfHr0cHVUIiKSVWgKTLKUpCQYPx6aNzeTnwcfhN27lfyIiIhjNAIkWUZMjDnltXmzedy7N7z9NuTK5dq4REQk63H5CNCcOXMoW7YsPj4+BAUFsW3btnTrrly5kpCQEPz9/cmbNy8NGjRgw4YNqer9888/DBw4kGLFiuHj40OVKlWIMO+NliwqMhJq1TKTHz8/+PRTc1VnJT8iInI3XJoALV++nGHDhvHqq6+yd+9eGjVqRIsWLYiOjk6z/nfffUdISAgRERHs2bOHpk2b0qZNG/bu3WutEx8fT0hICMePH2fFihUcOnSI999/nxIlSjjrtCQDJSbC6NHw+OPmRc81asCePdC5s6sjExGRrMylU2AzZsygd+/e9OnTB4BZs2axYcMG5s6dy6RJk1LVnzVrls3xxIkTWb16NWvXrqV27doALFiwgAsXLhAVFYWnp7kAXunSpTP3RCRTnDhhXuicMijYvz/MmGFe9CwiInIvXJYAxcfHs2fPHkaNGmVTHhoaSlRUlF1tJCcnc+nSJQoWLGgtW7NmDQ0aNGDgwIGsXr0af39/OnXqxMsvv4y7u3ua7dy4cYMbN25Yj+Pi4gBISEggIYPvp05pL6PbzW6+/tpCz57unD9vIU8eg7lzk2jf3gDsu8Vd/ewc6mfnUD87j/raOTKrnx1pz2UJ0Llz50hKSiIgIMCmPCAggNjYWLvamD59OleuXKF9+/bWsqNHj7J582Y6d+5MREQEf/75JwMHDiQxMZHXXnstzXYmTZrE+PHjU5Vv3LiRXJl0kUlkyuI1YiMx0cLixVVYteoBAMqV+4eXXtpN7txXuJvLuNTPzqF+dg71s/Oor50jo/v56tWrdtd1+V1glluW6zUMI1VZWpYuXcq4ceNYvXo1RYoUsZYnJydTpEgR5s+fj7u7O0FBQZw6dYo333wz3QQoPDycsLAw63FcXByBgYGEhoaSN2/euzyztCUkJBAZGUlISIh1ik5M0dHQpYs7u3aZl6YNHJjE5Ml+eHs3cbgt9bNzqJ+dQ/3sPOpr58isfk6ZwbGHyxKgwoUL4+7unmq058yZM6lGhW61fPlyevfuzeeff07z5s1tHitWrBienp42011VqlQhNjaW+Ph4vLy8UrXn7e2Nt7d3qnJPT89M+wPIzLazojVrzLV8Ll6EfPlgwQJ45hl3IO1pS3upn51D/ewc6mfnUV87R0b3syNtuewuMC8vL4KCglINf0VGRhIcHJzu85YuXUqPHj1YsmQJrVq1SvV4w4YNOXz4MMnJydayP/74g2LFiqWZ/IhrxcdDWBg8+aSZ/NStC3v3wjPPuDoyERHJzlx6G3xYWBgffPABCxYs4ODBgwwfPpzo6Gj69+8PmFNT3bp1s9ZfunQp3bp1Y/r06dSvX5/Y2FhiY2P5999/rXVeeOEFzp8/z9ChQ/njjz/46quvmDhxIgMHDnT6+cntHTsGjRrBzJnmcVgYbN8OZcu6Ni4REcn+XHoNUIcOHTh//jwTJkwgJiaGatWqERERYb1tPSYmxmZNoHnz5pGYmMjAgQNtEpru3buzaNEiAAIDA9m4cSPDhw+nRo0alChRgqFDh/Lyyy879dzk9lauhF694N9/oUAB+OgjaNPG1VGJiEhO4fKLoAcMGMCAAQPSfCwlqUmxZcsWu9ps0KABu3btusfIJDPcuAEvvgjvvmseN2gAy5ZBqVKujUtERHIWl2+FITnH4cMQHPy/5GfkSNi6VcmPiIg4n8tHgCRnWL4cnn8eLl2CwoXh44+hRQtXRyUiIjmVRoAkU127Zm5h8dxzZvLTqBHs26fkR0REXEsJkGSaQ4egfn2YNw8sFnNT082bQfvSioiIq2kKTDLFp5+aIz9XrkCRIuZxSIiroxIRETFpBEgy1NWr0Ls3dO1qJj9Nm5pTXkp+RETkfqIESDLMgQNQr565jYXFAuPGQWQkFCvm6shERERsaQpMMsSiRTBggHnRc9GisGSJOfojIiJyP9IIkNyTy5ehe3fo2dNMfkJD4eeflfyIiMj9TQmQ3LVffzU3L/34Y3BzgzfegPXrzYueRURE7meaAhOHGQZ88AEMGQLXr5u3tS9daq7xIyIikhUoARKHxMVBv37m/l0ALVuaG5kWLuzauERERByhKTCx2969EBRkJj8eHjB1Kqxdq+RHRESyHo0AyR0ZBsydC8OHQ3y8uXnpsmXmTu4iIiJZkRIgua1//4U+fWDFCvO4bVtYuBAKFnRtXCIiIvdCU2CSrh9/hNq1zeTH0xNmzoQvv1TyIyIiWZ9GgCQVw4C334aXXoKEBChbFpYvN295FxERyQ6UAImNCxegVy9Yvdo8fvZZ85b3/PldGpaIiEiG0hSYWO3aZU55rV4NXl7w7rvw+edKfkREJPtRAiQkJ8O0aeZChtHRUKGCmQwNHGhuaioiIpLdaAoshzt3Dnr0gK++Mo+few7mzYO8eV0aloiISKZSApSDbd8OHTvCiRPg4wNvvQXPP69RHxERyf40BZYDJSfDpEnw6KNm8lOpEnz/PfTtq+RHRERyBo0A5TBnzkDXrrBxo3nctSvMmQO5c7s2LhEREWdSApSDbNkCnTpBTAz4+sLs2eb1Pxr1ERGRnEZTYDlAUhJMmADNmpnJT9Wq5irPPXsq+RERkZxJI0DZXGwsdO4Mmzebx716wTvvQK5cro1LRETElZQAZWPffGMmP2fOgJ8fvPcedOni6qhERERcT1Ng2VBiIowZA6GhZvJTowbs3q3kR0REJIVGgLKZkyfNC52/+8487tfP3MXd19e1cYmIiNxPlABlI19/bd7Wfu4c5MkD8+ebKzuLiIiILU2BZQMJCTBqFLRoYSY/tWvDTz8p+REREUmPRoCyuOhoczuLqCjzeNAgePNNc2sLERERSZsSoCxs7VpzIcMLFyBfPvjwQ3j2WVdHJSIicv9z+RTYnDlzKFu2LD4+PgQFBbFt27Z0665cuZKQkBD8/f3JmzcvDRo0YMOGDenWX7ZsGRaLhaeeeioTIned+HgYMQLatjWTn7p1zSkvJT8iIiL2cWkCtHz5coYNG8arr77K3r17adSoES1atCA6OjrN+t999x0hISFERESwZ88emjZtSps2bdi7d2+qun/99RcvvvgijRo1yuzTcKpjx6BRI5gxwzwePtzc1b1cOdfGJSIikpW4NAGaMWMGvXv3pk+fPlSpUoVZs2YRGBjI3Llz06w/a9YsRo4cSd26dXnggQeYOHEiDzzwAGvXrrWpl5SUROfOnRk/fjzlslFmsGqVeYHzDz9AgQKwerWZCHl5uToyERGRrMVl1wDFx8ezZ88eRo0aZVMeGhpKVMoVvXeQnJzMpUuXKFiwoE35hAkT8Pf3p3fv3redUktx48YNbty4YT2Oi4sDICEhgYSEBLtisVdKe460e+MGjBrlxuzZ7gDUr5/MJ58kUbq0eQeYpHY3/SyOUz87h/rZedTXzpFZ/exIey5LgM6dO0dSUhIBAQE25QEBAcTGxtrVxvTp07ly5Qrt27e3lu3YsYMPP/yQffv22R3LpEmTGD9+fKryjRs3kiuTNs2KjIy0q15MTC6mTavLkSP5AXj66T/p3Pkg+/cb7N+fKaFlK/b2s9wb9bNzqJ+dR33tHBndz1evXrW7rsvvArPcsh25YRipytKydOlSxo0bx+rVqylSpAgAly5dokuXLrz//vsULlzY7hjCw8MJCwuzHsfFxREYGEhoaCh58+a1ux17JCQkEBkZSUhICJ6enret+/nnFkaOdOfSJQuFChksWJBEixZlgDIZGlN25Eg/y91TPzuH+tl51NfOkVn9nDKDYw+XJUCFCxfG3d091WjPmTNnUo0K3Wr58uX07t2bzz//nObNm1vLjxw5wvHjx2nTpo21LDk5GQAPDw8OHTpE+fLlU7Xn7e2Nt7d3qnJPT89M+wO4XdvXr5sXN7/3nnn8yCOwdKmFkiVdnq9mOZn5O5T/UT87h/rZedTXzpHR/exIWy67CNrLy4ugoKBUw1+RkZEEBwen+7ylS5fSo0cPlixZQqtWrWweq1y5Mr/++iv79u2z/rRt25amTZuyb98+AgMDM+VcMtIff0D9+mbyY7HAq6/Ct99CyZKujkxERCT7cOmQQlhYGF27dqVOnTo0aNCA+fPnEx0dTf/+/QFzaurkyZN8/PHHgJn8dOvWjbfeeov69etbR498fX3Jly8fPj4+VKtWzeY18ufPD5Cq/H60eLG5eemVK+Dvbx6HhLg6KhERkezHpQlQhw4dOH/+PBMmTCAmJoZq1aoRERFB6dKlAYiJibFZE2jevHkkJiYycOBABg4caC3v3r07ixYtcnb4GebqVRgyxFzJGaBpUzP5KVbMtXGJiIhkVy6/qGTAgAEMGDAgzcduTWq2bNnicPv3U2KUlARbt1r47rsS+PlZaNoUDh2C9u1h/35zymvsWBg9GtzdXR2tiIhI9uXyBCinWLkShg6FEyc8gDrMmGEuZnjlirm1RdGisGSJOfojIiIimUsJkBOsXAnt2oFh2JZfvGj+t0YN2LgR7nDzm4iIiGQQl2+Gmt0lJZkjP7cmPze7eBEcWLZIRERE7pESoEy2bRucOHH7On//bdYTERER51AClMliYjK2noiIiNw7JUCZzN5b2XXLu4iIiPMoAcpkjRqZqzint72ZxQKBgWY9ERERcQ4lQJnM3R3eesv8/1uToJTjWbO07o+IiIgzKQFygmeegRUroEQJ2/KSJc3yZ55xTVwiIiI5ldYBcpJnnoEnn4Rvv01k/fp9tGhRi6ZNPTTyIyIi4gJKgJzI3R2aNDG4cuUkTZrUVPIjIiLiIpoCExERkRxHCZCIiIjkOEqAREREJMdRAiQiIiI5jhIgERERyXGUAImIiEiOowRIREREchwlQCIiIpLjKAESERGRHEcrQafBMAwA4uLiMrzthIQErl69SlxcHJ6enhnevpjUz86hfnYO9bPzqK+dI7P6OeV7O+V7/HaUAKXh0qVLAAQGBro4EhEREXHUpUuXyJcv323rWAx70qQcJjk5mVOnTpEnTx4sFkuGth0XF0dgYCB///03efPmzdC25X/Uz86hfnYO9bPzqK+dI7P62TAMLl26RPHixXFzu/1VPhoBSoObmxslS5bM1NfImzev/ricQP3sHOpn51A/O4/62jkyo5/vNPKTQhdBi4iISI6jBEhERERyHCVATubt7c3YsWPx9vZ2dSjZmvrZOdTPzqF+dh71tXPcD/2si6BFREQkx9EIkIiIiOQ4SoBEREQkx1ECJCIiIjmOEiARERHJcZQAZaDvvvuONm3aULx4cSwWC19++eUdn7N161aCgoLw8fGhXLlyvPfee5kfaDbgaF+vXLmSkJAQ/P39yZs3Lw0aNGDDhg3OCTYLu5v3dIodO3bg4eFBrVq1Mi2+7OJu+vnGjRu8+uqrlC5dGm9vb8qXL8+CBQsyP9gs7G76efHixdSsWZNcuXJRrFgxevbsyfnz5zM/2Cxs0qRJ1K1blzx58lCkSBGeeuopDh06dMfnOfv7UAlQBrpy5Qo1a9bk3Xfftav+sWPHaNmyJY0aNWLv3r288sorDBkyhC+++CKTI836HO3r7777jpCQECIiItizZw9NmzalTZs27N27N5Mjzdoc7ecU//77L926daNZs2aZFFn2cjf93L59ezZt2sSHH37IoUOHWLp0KZUrV87EKLM+R/t5+/btdOvWjd69e7N//34+//xzfvzxR/r06ZPJkWZtW7duZeDAgezatYvIyEgSExMJDQ3lypUr6T7HJd+HhmQKwFi1atVt64wcOdKoXLmyTVm/fv2M+vXrZ2Jk2Y89fZ2WqlWrGuPHj8/4gLIpR/q5Q4cOxujRo42xY8caNWvWzNS4sht7+nn9+vVGvnz5jPPnzzsnqGzInn5+8803jXLlytmUvf3220bJkiUzMbLs58yZMwZgbN26Nd06rvg+1AiQC+3cuZPQ0FCbsscff5zdu3eTkJDgoqhyhuTkZC5dukTBggVdHUq2s3DhQo4cOcLYsWNdHUq2tWbNGurUqcPUqVMpUaIEFStW5MUXX+TatWuuDi1bCQ4O5sSJE0RERGAYBqdPn2bFihW0atXK1aFlKf/++y/AbT9vXfF9qM1QXSg2NpaAgACbsoCAABITEzl37hzFihVzUWTZ3/Tp07ly5Qrt27d3dSjZyp9//smoUaPYtm0bHh76eMksR48eZfv27fj4+LBq1SrOnTvHgAEDuHDhgq4DykDBwcEsXryYDh06cP36dRITE2nbti3vvPOOq0PLMgzDICwsjEceeYRq1aqlW88V34caAXIxi8Vic2z8/8Lct5ZLxlm6dCnjxo1j+fLlFClSxNXhZBtJSUl06tSJ8ePHU7FiRVeHk60lJydjsVhYvHgx9erVo2XLlsyYMYNFixZpFCgDHThwgCFDhvDaa6+xZ88evv76a44dO0b//v1dHVqWMWjQIH755ReWLl16x7rO/j7UP9FcqGjRosTGxtqUnTlzBg8PDwoVKuSiqLK35cuX07t3bz7//HOaN2/u6nCylUuXLrF792727t3LoEGDAPOL2jAMPDw82LhxI4899piLo8weihUrRokSJciXL5+1rEqVKhiGwYkTJ3jggQdcGF32MWnSJBo2bMhLL70EQI0aNfDz86NRo0a8/vrrGqW/g8GDB7NmzRq+++47SpYsedu6rvg+VALkQg0aNGDt2rU2ZRs3bqROnTp4enq6KKrsa+nSpfTq1YulS5dqDj8T5M2bl19//dWmbM6cOWzevJkVK1ZQtmxZF0WW/TRs2JDPP/+cy5cvkzt3bgD++OMP3Nzc7vhFI/a7evVqqqlcd3d34H+jE5KaYRgMHjyYVatWsWXLFrv+9l3xfagpsAx0+fJl9u3bx759+wDztr59+/YRHR0NQHh4ON26dbPW79+/P3/99RdhYWEcPHiQBQsW8OGHH/Liiy+6IvwsxdG+Xrp0Kd26dWP69OnUr1+f2NhYYmNjrRfnSdoc6Wc3NzeqVatm81OkSBF8fHyoVq0afn5+rjqN+56j7+dOnTpRqFAhevbsyYEDB/juu+946aWX6NWrF76+vq44hSzB0X5u06YNK1euZO7cuRw9epQdO3YwZMgQ6tWrR/HixV1xClnCwIED+fTTT1myZAl58uSxft7ePD17X3wfZtr9ZTnQt99+awCpfrp3724YhmF0797daNKkic1ztmzZYtSuXdvw8vIyypQpY8ydO9f5gWdBjvZ1kyZNbltf0nY37+mb6TZ4+9xNPx88eNBo3ry54evra5QsWdIICwszrl696vzgs5C76ee3337bqFq1quHr62sUK1bM6Ny5s3HixAnnB5+FpNXHgLFw4UJrnfvh+9Dy/8GKiIiI5BiaAhMREZEcRwmQiIiI5DhKgERERCTHUQIkIiIiOY4SIBEREclxlACJiIhIjqMESERERHIcJUAiWcjx48exWCzWlWzvB7///jv169fHx8eHWrVqZWjbjz76KMOGDcuw9saNG5fhMd6PvxMRuTMlQCIO6NGjBxaLhcmTJ9uUf/nll5m2Y/H9buzYsfj5+XHo0CE2bdqUZp2UfrNYLHh6elKuXDlefPFFrly5ctu2V65cyX//+98Mi/XFF19MN8bMdvjwYXr27EnJkiXx9vambNmydOzYkd27d7sknvtVRie9IulRAiTiIB8fH6ZMmcLFixddHUqGiY+Pv+vnHjlyhEceeYTSpUvfdtfmJ554gpiYGI4ePcrrr7/OnDlz0t3nJyEhAYCCBQuSJ0+eu47tVrlz5860naVvZ/fu3QQFBfHHH38wb948Dhw4wKpVq6hcuTIjRoxwejwiogRIxGHNmzenaNGiTJo0Kd06aU21zJo1izJlyliPe/TowVNPPcXEiRMJCAggf/78jB8/nsTERF566SUKFixIyZIlWbBgQar2f//9d4KDg/Hx8eHBBx9ky5YtNo8fOHCAli1bkjt3bgICAujatSvnzp2zPv7oo48yaNAgwsLCKFy4MCEhIWmeR3JyMhMmTLCOWtSqVYuvv/7a+rjFYmHPnj1MmDABi8XCuHHj0u0Tb29vihYtSmBgIJ06daJz5858+eWXNv21YMECypUrh7e3N4ZhpBoNKFOmDBMnTqRXr17kyZOHUqVKMX/+fJvXOXHiBM899xwFCxbEz8+POnXq8P3339u8zq2/g/Hjx1OkSBHy5s1Lv379bBLCr7/+mkceeYT8+fNTqFAhWrduzZEjR9I9z1sZhkGPHj144IEH2LZtG61ataJ8+fLUqlWLsWPHsnr1amvdX3/9lcceewxfX18KFSpE3759uXz5cqp4HXnPpEzRLVu27Lbvma1bt1KvXj28vb0pVqwYo0aNIjEx0fr4o48+ypAhQxg5ciQFCxakaNGiqX7f//77L3379rX25WOPPcbPP/9sfTyl/z/55BPKlClDvnz5eO6557h06ZL1/LZu3cpbb71lHTE8fvw4Fy9epHPnzvj7++Pr68sDDzzAwoUL7f4diKRFCZCIg9zd3Zk4cSLvvPMOJ06cuKe2Nm/ezKlTp/juu++YMWMG48aNo3Xr1hQoUIDvv/+e/v37079/f/7++2+b57300kuMGDGCvXv3EhwcTNu2bTl//jwAMTExNGnShFq1arF7926+/vprTp8+Tfv27W3a+Oijj/Dw8GDHjh3Mmzcvzfjeeustpk+fzrRp0/jll194/PHHadu2LX/++af1tR588EFGjBhBTEyMQzs3+/r6Wkd6wJwi+uyzz/jiiy9uez3N9OnTqVOnDnv37mXAgAG88MIL/P7774C523eTJk04deoUa9as4eeff2bkyJEkJyen296mTZs4ePAg3377LUuXLmXVqlWMHz/e+viVK1cICwvjxx9/ZNOmTbi5ufH000/fts2b7du3j/379zNixAjc3FJ/5ObPnx+Aq1ev8sQTT1CgQAF+/PFHPv/8c7755hsGDRpkUz8z3jMnT56kZcuW1K1bl59//pm5c+fy4Ycf8vrrr9u08dFHH+Hn58f333/P1KlTmTBhApGRkYCZ6LVq1YrY2FgiIiLYs2cPDz30EM2aNePChQvWNo4cOcKXX37JunXrWLduHVu3brVOKb/11ls0aNCA559/npiYGGJiYggMDGTMmDEcOHCA9evXc/DgQebOnUvhwoXt6n+RdGXqVqsi2Uz37t2NJ5980jAMw6hfv77Rq1cvwzAMY9WqVcbNf05p7YI+c+ZMo3Tp0jZtlS5d2khKSrKWVapUyWjUqJH1ODEx0fDz8zOWLl1qGIZhHDt2zACMyZMnW+skJCQYJUuWNKZMmWIYhmGMGTPGCA0NtXntv//+2wCMQ4cOGYZhGE2aNDFq1ap1x/MtXry48cYbb9iU1a1b1xgwYID1uGbNmsbYsWNv287N/WYYhvH9998bhQoVMtq3b28Yhtlfnp6expkzZ2ye16RJE2Po0KHW49KlSxtdunSxHicnJxtFihSx7ho9b948I0+ePMb58+fTjOPW30v37t2NggULGleuXLGWzZ0718idO7fN7+VmZ86cMQDj119/NQzjf7+TvXv3pll/+fLlBmD89NNPaT6eYv78+UaBAgWMy5cvW8u++uorw83NzYiNjbXGmxnvmVdeecWoVKmSkZycbK0ze/Zsm35o0qSJ8cgjj9jEXLduXePll182DMMwNm3aZOTNm9e4fv26TZ3y5csb8+bNMwzD7P9cuXIZcXFx1sdfeukl4+GHH7Ye3/o7NwzDaNOmjdGzZ8/b9p+IozQCJHKXpkyZwkcffcSBAwfuuo0HH3zQZlQgICCA6tWrW4/d3d0pVKgQZ86csXlegwYNrP/v4eFBnTp1OHjwIAB79uzh22+/JXfu3NafypUrA9hM3dSpU+e2scXFxXHq1CkaNmxoU96wYUPrazli3bp15M6dGx8fHxo0aEDjxo155513rI+XLl0af3//O7ZTo0YN6/9bLBaKFi1q7Z99+/ZRu3ZtChYsaHdcNWvWJFeuXNbjBg0acPnyZesIypEjR+jUqRPlypUjb968lC1bFoDo6Gi72jcMwxrr7Rw8eJCaNWvi5+dnLWvYsCHJyckcOnTIWpYZ75mDBw/SoEEDmxgbNmzI5cuXbUY5b+57gGLFillfZ8+ePVy+fJlChQrZvPeOHTtm874rU6aMzXVdN7eRnhdeeIFly5ZRq1YtRo4cSVRU1G3ri9jDw9UBiGRVjRs35vHHH+eVV16hR48eNo+5ublZv/hS3Dzdk8LT09PmOOUuqVvL7JluSfnySk5Opk2bNkyZMiVVnWLFiln//+YvWnvaTWEYxl3d8da0aVPmzp2Lp6cnxYsXT3We9sZzu/7x9fV1OK70pJxjmzZtCAwM5P3336d48eIkJydTrVo1uy8cr1ixImAmGbe7Bf92/XpzeWa8Z9J67bQSt9u9TnJyMsWKFUt1bRH8b5rvTm2kp0WLFvz111989dVXfPPNNzRr1oyBAwcybdq025+gyG1oBEjkHkyePJm1a9em+hepv78/sbGxNklQRq4Ts2vXLuv/JyYmsmfPHusoz0MPPcT+/fspU6YMFSpUsPmxN8kAyJs3L8WLF2f79u025VFRUVSpUsXhmP38/KhQoQKlS5dO9SWYUWrUqMG+fftsrjm5k59//plr165Zj3ft2kXu3LkpWbIk58+f5+DBg4wePZpmzZpRpUoVh+/+q1WrFlWrVmX69OlpftH/888/AFStWpV9+/bZLA2wY8cO3NzcrEnUvbjde6Zq1apERUXZvF+joqLIkycPJUqUsKv9hx56iNjYWDw8PFK97xy5XsfLy4ukpKRU5f7+/vTo0YNPP/2UWbNmpbr4XcRRSoBE7kH16tXp3LmzzVQOmHfMnD17lqlTp3LkyBFmz57N+vXrM+x1Z8+ezapVq/j9998ZOHAgFy9epFevXgAMHDiQCxcu0LFjR3744QeOHj3Kxo0b6dWrV5pfLLfz0ksvMWXKFJYvX86hQ4cYNWoU+/btY+jQoRl2LhmpY8eOFC1alKeeeoodO3Zw9OhRvvjiC3bu3Jnuc+Lj4+ndu7f1ItuxY8cyaNAg3NzcKFCgAIUKFWL+/PkcPnyYzZs3ExYW5lBMFouFhQsX8scff9C4cWMiIiI4evQov/zyC2+88QZPPvkkAJ07d8bHx4fu3bvz22+/8e233zJ48GC6du1KQEDAPfUL3P49M2DAAP7++28GDx7M77//zurVqxk7dixhYWFpXridlubNm9OgQQOeeuopNmzYwPHjx4mKimL06NEOrXVUpkwZvv/+e44fP865c+dITk7mtddeY/Xq1Rw+fJj9+/ezbt26u0rCRW6mBEjkHv33v/9NNd1VpUoV5syZw+zZs6lZsyY//PCDQ3dI3cnkyZOZMmUKNWvWZNu2baxevdr6r+zixYuzY8cOkpKSePzxx6lWrRpDhw4lX758dn+ZpRgyZAgjRoxgxIgRVK9ena+//po1a9bwwAMPZNi5ZCQvLy82btxIkSJFaNmyJdWrV2fy5Mm4u7un+5xmzZrxwAMP0LhxY9q3b0+bNm2st3e7ubmxbNky9uzZQ7Vq1Rg+fDhvvvmmw3HVq1eP3bt3U758eZ5//nmqVKlC27Zt2b9/P7NmzQIgV65cbNiwgQsXLlC3bl3atWtHs2bNePfdd++mK1K53XumRIkSRERE8MMPP1CzZk369+9P7969GT16tN3tWywWIiIiaNy4Mb169aJixYo899xzHD9+3KEE7sUXX8Td3Z2qVavi7+9PdHQ0Xl5ehIeHU6NGDRo3boy7uzvLli1zuA9EbmYxbv3kFhHJIXr06ME///xjXY8oOzp+/Dhly5Zl7969Gb4NiEhWphEgERERyXGUAImIiEiOoykwERERyXE0AiQiIiI5jhIgERERyXGUAImIiEiOowRIREREchwlQCIiIpLjKAESERGRHEcJkIiIiOQ4SoBEREQkx1ECJCIiIjnO/wFcRbm9iy6lxQAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["X_pca = apply_PCA(X, 2)"]},{"cell_type":"markdown","metadata":{},"source":["## Decision Tree"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Definir un espacio de bÃºsqueda mÃ¡s amplio para la bÃºsqueda de cuadrÃ­cula\n","param_grid = {\n","    'max_depth': [None, 3, 5, 8, 10],\n","    'min_samples_split': [2, 5, 10, 20],\n","    'min_samples_leaf': [1, 2, 4, 8],\n","    'max_features': ['sqrt', 'log2', None]\n","}\n","\n","param_grid = {\n","    'max_depth': [None, 3, 5, 8, 10],\n","    'min_samples_split': [2, 5, 10, 15, 20],\n","    'min_samples_leaf': [1, 2, 4, 8, 12],\n","    'max_features': ['sqrt', 'log2', None],\n","    'criterion': ['gini', 'entropy'],\n","    'splitter': ['best', 'random'],\n","    'max_leaf_nodes': [None, 10, 20, 30],\n","    'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3],\n","    'class_weight': [None, 'balanced']\n","}\n","\n","\n","clf = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n","\n","output = run_halving_grid_search(X, y, clf, param_grid)\n","\n","output = run_halving_grid_search(X_pca, y, clf, param_grid)"]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Best parameters: {'bootstrap': True, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n","\n","Mean Accuracy in cross-validation: 0.619241103848947\n","Standard Deviation of Accuracy in cross-validation: 0.06364876631487318\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Best parameters: {'bootstrap': True, 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n","\n","Mean Accuracy in cross-validation: 0.6792588053740014\n","Standard Deviation of Accuracy in cross-validation: 0.06977601295264185\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n","\n","param_grid = {\n","    'n_estimators': [50, 100, 200, 300],\n","    'max_depth': [None, 5, 10, 15, 20],\n","    'min_samples_split': [2, 5, 10, 15],\n","    'min_samples_leaf': [1, 2, 4, 8],\n","    'max_features': ['sqrt', 'log2', None],\n","    'bootstrap': [True, False],\n","    'criterion': ['gini', 'entropy'],\n","    'max_samples': [None, 0.8, 0.9, 1.0],  # Solo para bootstrap=True\n","    'oob_score': [True, False],\n","    'class_weight': [None, 'balanced', 'balanced_subsample']\n","}\n","\n","param_grid = {\n","    'n_estimators': [50, 100, 200, 300],\n","    'max_depth': [None, 5, 10, 15, 20],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['sqrt', 'log2', None],\n","    'bootstrap': [True, False]\n","}\n","\n","output = run_halving_grid_search(X, y, clf, param_grid)\n","\n","output = run_halving_grid_search(X_pca, y, clf, param_grid)"]},{"cell_type":"markdown","metadata":{},"source":["## SVM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = SVC(class_weight='balanced', random_state=42)\n","\n","# Definir el espacio de bÃºsqueda\n","param_grid = {\n","    'kernel': ['linear', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'gamma': ['scale', 'auto']\n","}\n","\n","param_grid = {\n","    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': ['scale', 'auto', 1e-3, 1e-4],\n","    'degree': [2, 3, 4],  # Solo para kernel 'poly'\n","    'coef0': [0.0, 0.1, 1.0]  # Solo para kernel 'poly' y 'sigmoid'\n","}\n","\n","output = run_halving_grid_search(X, y, clf, param_grid)\n","\n","output = run_halving_grid_search(X_pca, y, clf, param_grid)"]},{"cell_type":"markdown","metadata":{},"source":["## Naive bayes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mejores parÃ¡metros: {'var_smoothing': 1.0}\n","\n","Valor medio de Accuracy en cross validation: 0.4920915032679738\n","DesviaciÃ³n estÃ¡ndar de Accuracy en cross validation: 0.08005570932144956\n","Mejores parÃ¡metros: {'var_smoothing': 0.01}\n","\n","Valor medio de Accuracy en cross validation: 0.5879831932773109\n","DesviaciÃ³n estÃ¡ndar de Accuracy en cross validation: 0.03683719056112774\n"]}],"source":["# Crear el clasificador Naive Bayes\n","clf = GaussianNB()\n","\n","# Definir el espacio de bÃºsqueda\n","param_grid = {\n","    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n","}\n","\n","output = run_halving_grid_search(X, y, clf, param_grid)\n","\n","output = run_halving_grid_search(X_pca, y, clf, param_grid)"]},{"cell_type":"markdown","metadata":{"id":"F0TD9s91ewIN"},"source":["## PerceptrÃ³n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mejores parÃ¡metros: {'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01, 'max_iter': 100}\n","\n","Valor medio de Accuracy en cross validation: 0.605011219880256\n","DesviaciÃ³n estÃ¡ndar de Accuracy en cross validation: 0.1035173496998715\n","Mejores parÃ¡metros: {'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1, 'max_iter': 100}\n","\n","Valor medio de Accuracy en cross validation: 0.5417261957256666\n","DesviaciÃ³n estÃ¡ndar de Accuracy en cross validation: 0.09689920644807425\n"]}],"source":["# Crear el clasificador PerceptrÃ³n Multicapa (MLP)\n","clf = MLPClassifier(random_state=42)\n","\n","# Definir el espacio de bÃºsqueda\n","param_grid = {\n","    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n","    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n","    'max_iter': [100, 200, 300, 400, 500],\n","    'learning_rate_init': [0.1, 0.01, 0.001, 0.0001]\n","}\n","\n","param_grid = {\n","    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n","    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n","    'max_iter': [100, 200, 300, 400, 500],\n","    'learning_rate_init': [0.1, 0.01, 0.001, 0.0001],\n","    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n","    'solver': ['lbfgs', 'sgd', 'adam'],\n","    'tol': [1e-4, 1e-3, 1e-2],\n","    'momentum': [0.9, 0.8, 0.7],\n","    'beta_1': [0.9, 0.8, 0.7],\n","    'beta_2': [0.999, 0.9, 0.8],\n","}\n","\n","\n","output = run_halving_grid_search(X, y, clf, param_grid)\n","\n","output = run_halving_grid_search(X_pca, y, clf, param_grid)"]},{"cell_type":"markdown","metadata":{"id":"tTfhXxDFwH14"},"source":["## XGBoost"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb Celda 54\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.8\u001b[39m, \u001b[39m0.9\u001b[39m, \u001b[39m1.0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mreg_lambda\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m output \u001b[39m=\u001b[39m run_halving_grid_search(X, y, clf, param_grid)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output \u001b[39m=\u001b[39m run_halving_grid_search(X_pca, y, clf, param_grid)\n","\u001b[1;32m/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb Celda 54\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m halving_grid_search \u001b[39m=\u001b[39m HalvingGridSearchCV(clf, param_grid, scoring\u001b[39m=\u001b[39mscoring, cv\u001b[39m=\u001b[39mstratified_kf, factor\u001b[39m=\u001b[39mfactor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Realizar la bÃºsqueda de cuadrÃ­cula con validaciÃ³n cruzada\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m halving_grid_search\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Obtener el mejor modelo de la bÃºsqueda de cuadrÃ­cula\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jyoung/Doctorado/notebooks/Segmented_embryo_classifier.ipynb#Y211sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m best_clf \u001b[39m=\u001b[39m halving_grid_search\u001b[39m.\u001b[39mbest_estimator_\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:257\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input_parameters(\n\u001b[1;32m    250\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    251\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[1;32m    252\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples_orig \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 257\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    259\u001b[0m \u001b[39m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_results_[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_index_]\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:361\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    354\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checked_cv_orig\n\u001b[1;32m    356\u001b[0m more_results \u001b[39m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: [itr] \u001b[39m*\u001b[39m n_candidates,\n\u001b[1;32m    358\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_resources\u001b[39m\u001b[39m\"\u001b[39m: [n_resources] \u001b[39m*\u001b[39m n_candidates,\n\u001b[1;32m    359\u001b[0m }\n\u001b[0;32m--> 361\u001b[0m results \u001b[39m=\u001b[39m evaluate_candidates(\n\u001b[1;32m    362\u001b[0m     candidate_params, cv, more_results\u001b[39m=\u001b[39;49mmore_results\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    365\u001b[0m n_candidates_to_keep \u001b[39m=\u001b[39m ceil(n_candidates \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor)\n\u001b[1;32m    366\u001b[0m candidate_params \u001b[39m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m~/Doctorado/.conda/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Crear el clasificador XGBoost\n","clf = xgb.XGBClassifier(random_state=42)\n","\n","# Definir el espacio de bÃºsqueda\n","param_grid = {\n","    'max_depth': [3, 5, 7],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'n_estimators': [50, 100, 200],\n","    'subsample': [0.8, 0.9, 1.0],\n","    'colsample_bytree': [0.8, 0.9, 1.0]\n","}\n","\n","param_grid = {\n","    'max_depth': [3, 5, 7, 10],\n","    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n","    'n_estimators': [50, 100, 200, 300],\n","    'subsample': [0.8, 0.9, 1.0],\n","    'colsample_bytree': [0.8, 0.9, 1.0],\n","    'gamma': [0, 0.1, 0.2, 0.3],\n","    'min_child_weight': [1, 3, 5],\n","    'reg_alpha': [0, 0.1, 0.5, 1],\n","    'reg_lambda': [0, 0.1, 1, 10],\n","}\n","\n","\n","output = run_halving_grid_search(X, y, clf, param_grid)\n","\n","output = run_halving_grid_search(X_pca, y, clf, param_grid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["143"]},"execution_count":285,"metadata":{},"output_type":"execute_result"}],"source":["len(features[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670526633260,"user":{"displayName":"Juan Diego Young","userId":"16464023669569824356"},"user_tz":180},"id":"IxRt384jyg9b"},"outputs":[{"data":{"text/plain":["\"\\nnombres =  ['size', 'volume_blast', 'radio_blast', 'volume_ICM', 'volume_blastocoel', 'ratio_vol_ICM', 'ratio_vol_blastoc', 'ratio_blastoc_ICM', 'perÃ­metros','circularidad', 'sum_im_bin', 'compacto', 'dissimilitude', 'contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'mean', 'std' ]\\nnombres =  ['size', 'volume_blast', 'radio_blast', 'volume_ICM', 'volume_blastocoel', 'ratio_vol_ICM', 'ratio_vol_blastoc', 'ratio_blastoc_ICM', 'per', 'per/volume_blast', 'compacto', 'diss', 'cont', 'hom', 'en', 'corr', 'ASM', 'mean', 'std', 'lumen', 'diss2', 'cont2', 'hom2', 'en2', 'corr2', 'mean2', 'std2', 'lumen2']\\ndef features_principales(best_model):\\n    \\n    feats_princ = []\\n    orden = np.flip(np.argsort(best_model.feature_importances_))\\n    #print(np.flip(np.sort(best_model.feature_importances_)))\\n    print(len(nombres))\\n    for i in range(len(orden)):\\n        feats_princ.append(nombres[orden[i]])\\n    return feats_princ\\n\\ndef features_values(best_model, names):\\n  vals = np.flip(np.sort(bestimator.feature_importances_))\\n  plt.figure(figsize=(10,5))\\n  ticks = np.arange(len(vals))\\n  labels = names\\n  plt.xticks(ticks, labels, rotation = 90)\\n  plt.bar(np.arange(len(vals)),vals)\\n\""]},"execution_count":220,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","nombres =  ['size', 'volume_blast', 'radio_blast', 'volume_ICM', 'volume_blastocoel', 'ratio_vol_ICM', 'ratio_vol_blastoc', 'ratio_blastoc_ICM', 'perÃ­metros','circularidad', 'sum_im_bin', 'compacto', 'dissimilitude', 'contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'mean', 'std' ]\n","nombres =  ['size', 'volume_blast', 'radio_blast', 'volume_ICM', 'volume_blastocoel', 'ratio_vol_ICM', 'ratio_vol_blastoc', 'ratio_blastoc_ICM', 'per', 'per/volume_blast', 'compacto', 'diss', 'cont', 'hom', 'en', 'corr', 'ASM', 'mean', 'std', 'lumen', 'diss2', 'cont2', 'hom2', 'en2', 'corr2', 'mean2', 'std2', 'lumen2']\n","def features_principales(best_model):\n","    \n","    feats_princ = []\n","    orden = np.flip(np.argsort(best_model.feature_importances_))\n","    #print(np.flip(np.sort(best_model.feature_importances_)))\n","    print(len(nombres))\n","    for i in range(len(orden)):\n","        feats_princ.append(nombres[orden[i]])\n","    return feats_princ\n","\n","def features_values(best_model, names):\n","  vals = np.flip(np.sort(bestimator.feature_importances_))\n","  plt.figure(figsize=(10,5))\n","  ticks = np.arange(len(vals))\n","  labels = names\n","  plt.xticks(ticks, labels, rotation = 90)\n","  plt.bar(np.arange(len(vals)),vals)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNFRDajsUvarjDj583bT1p8","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
